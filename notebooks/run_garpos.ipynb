{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da2efe00-6b9a-497f-9faa-725c79ebe605",
   "metadata": {},
   "source": [
    "## This notebook demonstrates how to run the [GARPOS](https://github.com/s-watanabe-jhod/garpos) software in the EarthScope GeoLab cloud environment.  \n",
    "06-05-2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57577d14-992a-4646-8b87-0c58868e2c9d",
   "metadata": {},
   "source": [
    "### GeoLab Basics\n",
    "\n",
    "GeoLab is the name of EarthScope's Jupyter Hub, which allows users to run code via Jupyter notebooks (or in a terminal) on EarthScope resources in AWS.  \n",
    "\n",
    "The `sfg-geolab` image comes pre-loaded with the software needed to process GNSS-A data. Each user has their own home directory `/home/jovyan` that is mounted to \n",
    "the image and any files kept there are accessibile only to that user and remain during future sessions.  \n",
    "\n",
    "### Data \n",
    "For the purposes of this GARPOS demo, we have pre-processed some `cascadia-gorda` data and stored the shot data in an S3 bucket accessible to all users of the GeoLab hub.\n",
    "\n",
    "Raw data is available via authenticated https from [https://data.earthscope.org/archive/seafloor](https://data.earthscope.org/archive/seafloor).  Where pre-processed data is not available, or you want to create your own, you would use the `SV3_data_preprocessing.ipynb` notebook first to generate a copy within your user directory on the hub.  \n",
    "\n",
    "### Metadata\n",
    "In order to simplify our interactions with the various metadata formats, we are translating all metadata into `site` and `vessel` json. We store and load these metadata from the S3 archive [https://data.earthscope.org/archive/seafloor/metadata](https://data.earthscope.org/archive/seafloor/metadata)\n",
    "\n",
    "### Results\n",
    "Results are stored per GARPOS run under `/home/joyvan/data/sfg/[network]/[station]/GARPOS/[campaign]/[survey]/results/`. \n",
    "\n",
    "### Logs\n",
    "Some log output is piped to the notebook.  Additionally those logs plus debug logs are written to `/home/joyvan/data/sfg/[network]/[station]/logs`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a283b5f-f1ee-4471-b58d-db393a5a00cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load required modules\n",
    "from es_sfgtools.data_mgmt.data_handler import DataHandler\n",
    "from es_sfgtools.utils.archive_pull import load_site_metadata\n",
    "import os\n",
    "\n",
    "# from sfg_metadata import GEOLAB_CATALOG\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = [32,18]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777b6139-4d1b-4e3a-bd5d-9fee96515f04",
   "metadata": {},
   "source": [
    "## Select the data you are interested in running through GARPOS\n",
    "Currently we have pre-processed the following campaigns and made shot data available to this environment in a shared S3 bucket.\n",
    "\n",
    "|  | GCC1 | NBR1 | NCC1 |\n",
    "|---|---|---|---|\n",
    "| **2022** |2022_A_1065 |   |   |\n",
    "| **2023** |   | 2023_A_1063 | 2023_A_1063 |\n",
    "| **2024** |   |   |  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c91504-ef95-4386-95b6-523ed09262d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the network, station, and campaign of interest\n",
    "network = \"cascadia-gorda\"\n",
    "station = \"NBR1\"\n",
    "campaign_name = '2023_A_1063'\n",
    "\n",
    "# This flag selects using our shared preprocessed data.  If false, you must first preprocess your own data \n",
    "# and have the shotdata available in your hub data directory\n",
    "use_shared_data = True\n",
    "\n",
    "\n",
    "#Initialize a data handler object for the selected campaign, this builds local directory structures and tracks \n",
    "#where data is written.  Do not edit this code.\n",
    "main_dir = Path.home()/\"data\"/\"sfg\"\n",
    "if use_shared_data:\n",
    "    dh = DataHandler(directory=main_dir)\n",
    "else:\n",
    "    dh = DataHandler(directory=main_dir)\n",
    "\n",
    "# Set the station and campaig\n",
    "dh.change_working_station(network=network, station=station, campaign=campaign_name)\n",
    "\n",
    "# Add site ctds to catalog\n",
    "dh.add_ctds_to_catalog()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0633e6ba-17dc-4591-b002-cdc749edac4a",
   "metadata": {},
   "source": [
    "## Load the required processing metadata for the selected station:\n",
    "This includes\n",
    "- station metadata\n",
    "  - array center\n",
    "  - benchmark/transponder info\n",
    "  - campaign/survey times\n",
    "- vessel metadata\n",
    "  - ATD offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef2fc0f-54ef-4d10-b726-eb851f190b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the metadata and view what surveys are in the selected campaign\n",
    "station_meta = load_site_metadata(network, station)\n",
    "for campaign in station_meta.campaigns:\n",
    "    if campaign.name == campaign_name:\n",
    "        surveys = campaign.surveys\n",
    "        print(f\"The campaign {station} {campaign.name} contains {len(surveys)} survey patterns\")\n",
    "        for survey in surveys:\n",
    "            print(f\"  Survey Name: {survey.id}\")\n",
    "            print(f\"     Survey Type: {survey.type} {survey.notes if survey.notes is not None else ''}\")\n",
    "            print(f\"     {survey.start} to {survey.end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c748ef-5b27-43b3-9b02-c8a189e075d3",
   "metadata": {},
   "source": [
    "## Set up the GARPOS runs\n",
    "\n",
    "This section prepares the input files needed to run GARPOS.  We are batching GARPOS runs by survey, so this step generates a set of files for each of the surveys listed above.\n",
    "\n",
    "Data files (input files and results) will be stored in the locally mounted filesystem under \n",
    "\n",
    "`/home/joyvan/data/sfg/[network]/[station]/GARPOS/[campaign_name]/[survey_name]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8af6752-6ed3-4721-8881-68c932a4f09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a garpos handler object, this is used to prep data and run the GARPOS software\n",
    "gp_handler = dh.get_garpos_handler(site_data=station_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c925aa-2816-4deb-9144-15ba920d7224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a sound speed profile input file.  Looks for a CTD in our s3 archive. Can also override with a local CTD file.\n",
    "gp_handler.load_sound_speed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05be2cf-52bc-441e-a2fe-a4595b14d67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you wish to override the default data filters, you can do so here. \n",
    "# Once added, pass the custom_filters dictionary to the prep_shotdata function below\n",
    "custom_filters = {'acoustic_filters': {'enabled': False, 'level': 'OK'}, \n",
    "                  'ping_replies': {'enabled': False, 'min_replies': 3}, \n",
    "                  'max_distance_from_center': {'enabled': False, 'max_distance_m': 150}, \n",
    "                  'pride_residuals': {'enabled': False, 'max_residual_mm': 5}}\n",
    "\n",
    "# Load the shot_data from the shared S3 bucket and write out the garpos obs input files\n",
    "gp_handler.prep_shotdata(overwrite=True)\n",
    "# customs_filters=custom_filters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c0bbd8-5c09-4efb-bfb3-b9b8cb95fb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the default GARPOS inversion parameters\n",
    "gp_handler.garpos_fixed.inversion_params.show_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c27db0c-8665-4a92-9d33-01496e55220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify GARPOS parameters if desired\n",
    "update_dict = {\n",
    "                \"rejectcriteria\": 2.5,\n",
    "                \"log_lambda\":[0],\n",
    "                \"maxloop\": 5 #to speed things up for the sake of demo\n",
    "            }\n",
    "gp_handler.set_inversion_params(update_dict)\n",
    "gp_handler.garpos_fixed.inversion_params.show_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270dfbc3-3fae-400b-9c8f-cd5a1e00267e",
   "metadata": {},
   "source": [
    "## Run GARPOS\n",
    "This will loop through all the surveys in the campaign and run GARPOS on each.  \n",
    "\n",
    "You can change the above inversion parameters and run again to compare results, but make sure to increment run_id so that the results are stored in a new directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107553b9-d7b1-48ca-9675-a2504ce91821",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = 1\n",
    "survey_number = 1\n",
    "survey_id=f\"{campaign_name}_{survey_number}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b3fc43-5eb8-4155-9cc7-23c3c53a843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_handler.run_garpos(survey_id=survey_id,\n",
    "                      run_id=run_id,\n",
    "                      override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffb7a6c-89f6-4f62-89b5-4dca99ddf7e7",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3a32f5-51b2-4848-9790-12b56984b774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib widget\n",
    "residual_filter = 25\n",
    "gp_handler.plot_ts_results(survey_id=survey_id,\n",
    "                           run_id=run_id,\n",
    "                           res_filter=residual_filter\n",
    "                          )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seafloor_geodesy_mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
