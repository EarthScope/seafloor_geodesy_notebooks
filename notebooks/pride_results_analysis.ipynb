{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pride Results Analysis\n",
    "This notebook is used to analyze the results file from PRIDE-PPPAR\n",
    "\n",
    "\n",
    "It assumes you have generated daily rinex and already run PRIDE on those files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select a site and survey\n",
    "\n",
    "# network='aleutian'\n",
    "# site='SEM1'\n",
    "# survey='2022_A_1049'\n",
    "\n",
    "network='cascadia-gorda'\n",
    "site='NCC1'\n",
    "survey='2022_A_1065'\n",
    "#survey='2023_A_1063'\n",
    "\n",
    "\n",
    "#point this at where you have the pride results\n",
    "pride_dir = f\"/Users/gottlieb/working/GIT/seafloor_geodesy_notebooks/notebooks/data/Pride/\"\n",
    "\n",
    "\n",
    "#rinex_dir = f\"/Users/gottlieb/working/GIT/seafloor_geodesy_notebooks/notebooks/data/{network}/{site}/{survey}/raw/\"\n",
    "#rinex_filename = f\"NCC1{dayOfYear}0.23o\"\n",
    "\n",
    "\n",
    "# dayOfYear = 129\n",
    "# year = survey.split('_')[0]\n",
    "# log_path = os.path.join(pride_dir, f\"log_{year}{dayOfYear}_{site}\")\n",
    "# kin_path = os.path.join(pride_dir, f\"kin_{year}{dayOfYear}_{site}\")\n",
    "# res_path = os.path.join(pride_dir, f\"res_{year}{dayOfYear}_{site}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check LOG file for epochs used vs removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_log_header(log_path):\n",
    "    log_header = {}\n",
    "    with open(log_path, \"r\") as file:\n",
    "        for i, line in enumerate(file):\n",
    "            if \"END OF HEADER\" in line:\n",
    "                end_of_header = i\n",
    "                break\n",
    "            log_header[line.rstrip()[60:]] = line.rstrip()[:60].strip()\n",
    "    return log_header\n",
    "\n",
    "def get_epochs_from_log(log_path):\n",
    "    log_header = read_log_header(log_path)\n",
    "    #print(log_header)\n",
    "    epo_ava = log_header['EPO AVA/REM/NEW'].split()[0]\n",
    "    epo_rem = log_header['EPO AVA/REM/NEW'].split()[1]\n",
    "    print(f\"Epochs used: {epo_ava}\")\n",
    "    print(f\"Epochs removed: {epo_rem}\")\n",
    "    print(f\"Percent used: {round(int(epo_ava)/(int(epo_ava)+int(epo_rem))*100,2)}\")\n",
    "\n",
    "#get_epochs_from_log(log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse and plot the KIN file (adding wrms from RES file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_kin_header(kin_path):\n",
    "    kin_header = {}\n",
    "    with open(kin_path, \"r\") as kin_file:\n",
    "        for i, line in enumerate(kin_file):\n",
    "            if \"END OF HEADER\" in line:\n",
    "                end_of_header = i\n",
    "                break\n",
    "            kin_header[line.rstrip()[60:]] = line.rstrip()[:60].strip()\n",
    "    return kin_header\n",
    "\n",
    "def parse_kin_header(kin_path):\n",
    "    kin_header = read_kin_header(kin_path)\n",
    "    keys = ['OBS STRICT EDITING','OBS FIRST EPOCH','OBS LAST EPOCH','OBS INTERVAL (sec)','OBS MASK ANGLE (deg)',\n",
    "            'MEASUREMENT NOISE PSEUDORANGE (1-SIGMA, meter)','MEASUREMENT NOISE CARRIER PHASE (1-SIGMA, cycle)',\n",
    "            'SITE ANTENNA TYPE','SITE ANTENNA E/N/H (meter)','AMB FIXING']\n",
    "    for key in kin_header:\n",
    "        if key in keys:\n",
    "            print(key, kin_header[key])\n",
    "\n",
    "def read_kin_data(kin_path):\n",
    "    with open(kin_path, \"r\") as kin_file:\n",
    "            for i, line in enumerate(kin_file):\n",
    "                if \"END OF HEADER\" in line:\n",
    "                    end_of_header = i + 1\n",
    "                    break\n",
    "    cols = [\"Mjd\",\"Sod\",\"*\",\"X\",\"Y\",\"Z\",\"Latitude\",\"Longitude\",\"Height\",\"Nsat\",\"G\",\"R\",\"E\",\"C2\",\"C3\",\"J\",\"PDOP\"]\n",
    "    colspecs = [(0,6),(6,16),(16,18),(18,32),(32,46),(46,60),(60,77),(77,94),(94,108),\n",
    "                (108,114),(114,117),(117,120),(120,123),(123,126),(126,129),(129,132),(132,140)]\n",
    "    kin_df = pd.read_fwf(kin_path, header=end_of_header, colspecs=colspecs, names=cols, on_bad_lines='skip')\n",
    "    #kin_df = pd.read_csv(kin_path, sep=\"\\s+\", names=cols, header=end_of_header, on_bad_lines='skip')\n",
    "    kin_df.set_index(pd.to_datetime(kin_df['Mjd']+2400000.5, unit='D',origin=\"julian\")+pd.to_timedelta(kin_df['Sod'], unit='sec'), inplace=True)\n",
    "    return kin_df\n",
    "\n",
    "#read res and caculate wrms\n",
    "def get_wrms_from_res(res_path):\n",
    "    with open(res_path, \"r\") as res_file:\n",
    "        timestamps = []\n",
    "        data = []\n",
    "        wrms = 0\n",
    "        sumOfSquares = 0\n",
    "        sumOfWeights = 0\n",
    "        line = res_file.readline() #first line is header and we can throw away\n",
    "        while True:\n",
    "            if line == \"\": #break at EOF\n",
    "                break\n",
    "            line_data = line.split()\n",
    "            if line_data[0] == 'TIM': #for a given epoch\n",
    "                sumOfSquares = 0\n",
    "                sumOfWeights = 0\n",
    "                #parse date fields and make a timestamp\n",
    "                seconds = float(line_data[6])\n",
    "                SS = int(seconds)\n",
    "                f = str(seconds - SS).split('.')[-1]\n",
    "                isodate = f\"{line_data[1]}-{line_data[2].zfill(2)}-{line_data[3].zfill(2)}T{line_data[4].zfill(2)}:{line_data[5].zfill(2)}:{str(SS).zfill(2)}.{f}\"\n",
    "                timestamp = datetime.fromisoformat(isodate)\n",
    "                timestamps.append(timestamp)\n",
    "                #loop through SV data for that epoch, stop at next timestamp\n",
    "                line = res_file.readline()\n",
    "                line_data = line.split()\n",
    "                while not line.startswith('TIM'):\n",
    "                    phase_residual = float(line_data[1])\n",
    "                    phase_weight = float(line_data[3].replace('D','E'))\n",
    "                    sumOfSquares += phase_residual**2 * phase_weight\n",
    "                    sumOfWeights += phase_weight\n",
    "                    line = res_file.readline()\n",
    "                    if line == \"\":\n",
    "                        break\n",
    "                    line_data = line.split()\n",
    "                wrms = (sumOfSquares/sumOfWeights)**0.5 * 1000 #in mm\n",
    "                data.append(wrms)\n",
    "            else:\n",
    "                line = res_file.readline()\n",
    "    res_df = pd.DataFrame({'date':timestamps,'wrms':data}).set_index('date')\n",
    "    return res_df\n",
    "\n",
    "#parse_kin_header(kin_path)\n",
    "#kin_df = read_kin_data(kin_path)\n",
    "#wrms_df = get_wrms_from_res(res_path)\n",
    "#kin_df['wrms']=wrms_df['wrms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kin_results(kin_df, title=None, save_as=None):\n",
    "    #use this one if you dont have wrms data\n",
    "    size=3\n",
    "    bad_nsat = kin_df[kin_df['Nsat']<=4]\n",
    "    bad_pdop = kin_df[kin_df['PDOP']>=5]\n",
    "    #bad_wrms = kin_df[kin_df['wrms']>=20]\n",
    "    fig, axs = plt.subplots(5,1, figsize=(10,10), sharex=True, )\n",
    "    axs[0].scatter(kin_df.index,kin_df['Latitude'],s=size)\n",
    "    axs[0].set_ylabel('Latitude')\n",
    "    axs[1].scatter(kin_df.index,kin_df['Longitude'],s=size)\n",
    "    axs[1].set_ylabel('Longitude')\n",
    "    axs[2].scatter(kin_df.index,kin_df['Height'],s=size)\n",
    "    axs[2].set_ylabel('Height')\n",
    "    axs[3].scatter(kin_df.index,kin_df['Nsat'],s=size)\n",
    "    axs[3].scatter(bad_nsat.index,bad_nsat['Nsat'],s=size*2, color='red')\n",
    "    axs[3].set_ylabel('Nsat')\n",
    "    axs[4].scatter(kin_df.index,kin_df['PDOP'],s=size)\n",
    "    axs[4].scatter(bad_pdop.index,bad_pdop['PDOP'],s=size*2, color='red')\n",
    "    axs[4].set_ylabel('log PDOP')\n",
    "    axs[4].set_yscale('log')\n",
    "    axs[4].set_ylim(1,100)\n",
    "    \n",
    "    axs[0].ticklabel_format(axis='y',useOffset=False, style='plain')\n",
    "    axs[1].ticklabel_format(axis='y',useOffset=False, style='plain')\n",
    "    for ax in axs:\n",
    "        ax.grid(True,c='lightgrey',zorder=0,lw=1,ls=':')\n",
    "    plt.xticks(rotation=70)\n",
    "    fig.suptitle(f\"PRIDE-PPPAR results for {os.path.basename(title)}\")\n",
    "    fig.tight_layout()\n",
    "    if save_as is not None:\n",
    "        plt.savefig(save_as)\n",
    "    plt.close()\n",
    "    print(f\"epochs with nsat <= 4: {round(len(bad_nsat)/len(kin_df)*100,2)} %\")\n",
    "    print(f\"epochs with PDOP >= 5: {round(len(bad_pdop)/len(kin_df)*100,2)} %\")\n",
    "    #print(f\"epochs with wrms >= 20: {round(len(bad_wrms)/len(kin_df)*100,2)} %\")\n",
    "\n",
    "def plot_kin_results_wrms(kin_df, title=None, save_as=None):\n",
    "    #use this one if you have wrms data\n",
    "    size=3\n",
    "    bad_nsat = kin_df[kin_df['Nsat']<=4]\n",
    "    bad_pdop = kin_df[kin_df['PDOP']>=5]\n",
    "    bad_wrms = kin_df[kin_df['wrms']>=20]\n",
    "    fig, axs = plt.subplots(6,1, figsize=(10,10), sharex=True, )\n",
    "    axs[0].scatter(kin_df.index,kin_df['Latitude'],s=size)\n",
    "    axs[0].set_ylabel('Latitude')\n",
    "    axs[1].scatter(kin_df.index,kin_df['Longitude'],s=size)\n",
    "    axs[1].set_ylabel('Longitude')\n",
    "    axs[2].scatter(kin_df.index,kin_df['Height'],s=size)\n",
    "    axs[2].set_ylabel('Height')\n",
    "    axs[3].scatter(kin_df.index,kin_df['Nsat'],s=size)\n",
    "    axs[3].scatter(bad_nsat.index,bad_nsat['Nsat'],s=size*2, color='red')\n",
    "    axs[3].set_ylabel('Nsat')\n",
    "    axs[4].scatter(kin_df.index,kin_df['PDOP'],s=size)\n",
    "    axs[4].scatter(bad_pdop.index,bad_pdop['PDOP'],s=size*2, color='red')\n",
    "    axs[4].set_ylabel('log PDOP')\n",
    "    axs[4].set_yscale('log')\n",
    "    axs[4].set_ylim(1,100)\n",
    "    axs[5].scatter(kin_df.index,kin_df['wrms'],s=size)\n",
    "    #axs[5].plot(kin_df['wrms'])\n",
    "    #axs[5].scatter(bad_wrms.index,bad_wrms['wrms'],s=size*2, color='red')\n",
    "    axs[5].set_ylabel('wrms mm')\n",
    "    #axs[5].set_yscale('log')\n",
    "    #axs[5].set_ylim(0,100)\n",
    "\n",
    "    axs[0].ticklabel_format(axis='y',useOffset=False, style='plain')\n",
    "    axs[1].ticklabel_format(axis='y',useOffset=False, style='plain')\n",
    "    for ax in axs:\n",
    "        ax.grid(True,c='lightgrey',zorder=0,lw=1,ls=':')\n",
    "    plt.xticks(rotation=70)\n",
    "    fig.suptitle(f\"PRIDE-PPPAR results for {os.path.basename(title)}\")\n",
    "    fig.tight_layout()\n",
    "    if save_as is not None:\n",
    "        plt.savefig(save_as)\n",
    "    plt.close()\n",
    "    print(f\"epochs with nsat <= 4: {round(len(bad_nsat)/len(kin_df)*100,2)} %\")\n",
    "    print(f\"epochs with PDOP >= 5: {round(len(bad_pdop)/len(kin_df)*100,2)} %\")\n",
    "    print(f\"epochs with wrms >= 20: {round(len(bad_wrms)/len(kin_df)*100,2)} %\")\n",
    "\n",
    "#plot_kin_results(kin_df, save_as = f\"{pride_dir}/kin_results.png\")\n",
    "#plot_kin_results_wrms(kin_df, save_as = f\"{pride_dir}/kin_results.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parse the res file to make the following plots\n",
    "- residuals vs elevation per sat\n",
    "- residuals vs time per sat\n",
    "- elevation vs time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_res_data(res_path):\n",
    "    with open(res_path, \"r\") as res_file:\n",
    "        data = []\n",
    "        line = res_file.readline() #first line we can throw away\n",
    "        while True: \n",
    "            if line == \"\":\n",
    "                break\n",
    "            line_data = line.split()\n",
    "            if line_data[0] == 'TIM':\n",
    "                seconds = float(line_data[6])\n",
    "                SS = int(seconds)\n",
    "                f = str(seconds - SS).split('.')[-1]\n",
    "                isodate = f\"{line_data[1]}-{line_data[2].zfill(2)}-{line_data[3].zfill(2)}T{line_data[4].zfill(2)}:{line_data[5].zfill(2)}:{str(SS).zfill(2)}.{f}\"\n",
    "                timestamp = datetime.fromisoformat(isodate)\n",
    "                #read data for that epoch\n",
    "                line = res_file.readline()\n",
    "                line_data = line.split()\n",
    "                while not line.startswith('TIM'):\n",
    "                    #print(line_data)\n",
    "                    prn = line_data[0]\n",
    "                    line_data[3] = float(line_data[3].replace('D','E'))\n",
    "                    line_data[4] = float(line_data[4].replace('D','E'))\n",
    "                    row = [timestamp]+line_data\n",
    "                    data.append(row)\n",
    "                    line = res_file.readline()\n",
    "                    if line == \"\":\n",
    "                        break\n",
    "                    line_data = line.split()\n",
    "            else:\n",
    "                line = res_file.readline()\n",
    "    res_df = pd.DataFrame(data, columns=['date','prn','phase_res','psuedorange_res','phase_weight','psuedorange_weight',\n",
    "                                          'data_status_id','elevation','azimuth','obs1','obs2','obs3','obs4'])\n",
    "    res_df=res_df.set_index(['date'])#,'prn'])\n",
    "    return res_df\n",
    "\n",
    "def get_satellites_from_res(res_path):\n",
    "    satellites = []\n",
    "    with open(res_path, \"r\") as res_file:\n",
    "        for i, line in enumerate(res_file):\n",
    "            if \"SATELLITE LIST\" in line:\n",
    "                line_data = line.split()\n",
    "                satellites += line_data[:-2]\n",
    "            if \"END OF HEADER\" in line:\n",
    "                end_of_header = i\n",
    "                break\n",
    "    return satellites\n",
    "\n",
    "# res_df = read_res_data(res_path)\n",
    "# satellites = get_satellites_from_res(res_path)\n",
    "# res_df = res_df[['prn','phase_res','elevation']].astype({'phase_res':'float','elevation':'float'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_res_v_elev(res_df,satellites, plot_title):\n",
    "    fig, axs = plt.subplots(len(satellites),1, figsize=(8,len(satellites)*1.5), sharex=False)\n",
    "    for i, prn in enumerate(satellites):\n",
    "        tmp_df = res_df[res_df['prn']==prn]\n",
    "        axs[i].scatter(tmp_df['elevation'],tmp_df['phase_res']*1000, s=2)\n",
    "        axs[i].set_ylabel(prn)\n",
    "        axs[i].set_ylim(-50,50)\n",
    "    axs[i].set_xlabel('elevation')\n",
    "    fig.suptitle(f\"Phase Residuals mm vs elevation angle for {os.path.basename(plot_title)}\")\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
    "    plt.savefig(f\"{pride_dir}/res_v_elev.png\")\n",
    "    plt.close()\n",
    "#plot_title = f\"{site}_{year}_{dayOfYear}\"\n",
    "#plot_res_v_elev(res_df,satellites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_res_v_time(res_df,satellites, plot_title):\n",
    "    fig, axs = plt.subplots(len(satellites),1, figsize=(8,len(satellites)*1.5), sharex=True)\n",
    "    for i, prn in enumerate(satellites):\n",
    "        tmp_df = res_df[res_df['prn']==prn]\n",
    "        axs[i].scatter(tmp_df.index,tmp_df['phase_res']*1000, s=2)\n",
    "        axs[i].set_ylabel(prn)\n",
    "        axs[i].set_ylim(-50,50)\n",
    "    axs[i].set_xlabel('elevation')\n",
    "    fig.suptitle(f\"Phase Residuals mm vs time for {os.path.basename(plot_title)}\")\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
    "    plt.savefig(f\"{pride_dir}/res_v_time.png\")\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "#plot_title = f\"{site}_{year}_{dayOfYear}\"\n",
    "#plot_res_v_time(res_df,satellites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_elev_v_time(res_df,satellites,plot_title):\n",
    "    fig, axs = plt.subplots(len(satellites),1, figsize=(8,len(satellites)*1.5), sharex=True)\n",
    "    for i, prn in enumerate(satellites):\n",
    "        tmp_df = res_df[res_df['prn']==prn]\n",
    "        axs[i].scatter(tmp_df.index,tmp_df['elevation'], s=2)\n",
    "        axs[i].set_ylabel(prn)\n",
    "        axs[i].set_ylim(0,90)\n",
    "    axs[i].set_xlabel('elevation')\n",
    "    fig.suptitle(f\"elevation vs time for {os.path.basename(plot_title)}\")\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
    "    plt.savefig(f\"{pride_dir}/elev_v_time.png\")\n",
    "    plt.close()\n",
    "#plot_title = f\"{site}_{year}_{dayOfYear}\"\n",
    "#plot_elev_v_time(res_df,satellites)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop through days in survey, parse results, and make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCC1 2022_A_1065 Day: 121\n",
      "NCC1 2022_A_1065 Day: 122\n",
      "[Errno 2] No such file or directory: '/Users/gottlieb/working/GIT/seafloor_geodesy_notebooks/notebooks/data/Pride/2022/122/res_2022122_NCC1'\n",
      "NCC1 2022_A_1065 Day: 123\n",
      "NCC1 2022_A_1065 Day: 124\n",
      "NCC1 2022_A_1065 Day: 125\n",
      "NCC1 2022_A_1065 Day: 126\n",
      "NCC1 2022_A_1065 Day: 127\n",
      "NCC1 2022_A_1065 Day: 128\n",
      "NCC1 2022_A_1065 Day: 129\n",
      "[Errno 2] No such file or directory: '/Users/gottlieb/working/GIT/seafloor_geodesy_notebooks/notebooks/data/Pride/2022/129/res_2022129_NCC1'\n",
      "NCC1 2022_A_1065 Day: 130\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# need to manually enter the dayOfYear range\n",
    "\n",
    "kin_df = None\n",
    "wrms_df = None\n",
    "year = survey.split('_')[0]\n",
    "for dayOfYear in range(121,131):\n",
    "    print(f\"{site} {survey} Day: {dayOfYear}\")\n",
    "    plot_title = f\"{site}_{year}_{dayOfYear}\"\n",
    "    daily_pride_dir = f\"{pride_dir}/{year}/{dayOfYear}\"\n",
    "    try:\n",
    "        #make the daily kin_results plots, build a full dataframe of kin results for whole survey\n",
    "        log_path = os.path.join(daily_pride_dir, f\"log_{year}{dayOfYear}_{site}\")\n",
    "        kin_path = os.path.join(daily_pride_dir, f\"kin_{year}{dayOfYear}_{site}\")\n",
    "        res_path = os.path.join(daily_pride_dir, f\"res_{year}{dayOfYear}_{site}\")\n",
    "        get_epochs_from_log(log_path)\n",
    "        if kin_df is None:\n",
    "            kin_df = read_kin_data(kin_path)\n",
    "            wrms_df = get_wrms_from_res(res_path)\n",
    "            kin_df['wrms']=wrms_df['wrms']\n",
    "            plot_kin_results_wrms(kin_df, title=plot_title, save_as=f\"{daily_pride_dir}/kin_results.png\")\n",
    "        else:\n",
    "            kin_df2 = read_kin_data(kin_path)\n",
    "            wrms_df2 = get_wrms_from_res(res_path)\n",
    "            kin_df2['wrms']=wrms_df2['wrms']\n",
    "            plot_kin_results_wrms(kin_df2, title=plot_title, save_as=f\"{daily_pride_dir}/kin_results.png\")\n",
    "            kin_df = pd.concat([kin_df, kin_df2])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    try:\n",
    "        #make extra daily plots\n",
    "        res_path = os.path.join(daily_pride_dir, f\"res_{year}{dayOfYear}_{site}\")\n",
    "        res_df = read_res_data(res_path)\n",
    "        satellites = get_satellites_from_res(res_path)\n",
    "        res_df = res_df[['prn','phase_res','elevation']].astype({'phase_res':'float','elevation':'float'})\n",
    "        plot_res_v_elev(res_df,satellites,plot_title)\n",
    "        plot_res_v_time(res_df,satellites,plot_title)\n",
    "        plot_elev_v_time(res_df,satellites,plot_title)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "#make the full survey kin_results plot\n",
    "plot_title = f\"{site}_{survey}\"\n",
    "plot_kin_results_wrms(kin_df, title=plot_title, save_as=f\"{pride_dir}/{year}/{survey}_kin_results.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seafloor_geodesy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
