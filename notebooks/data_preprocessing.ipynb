{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "This notebook runs a user through the steps to select a survey and preprocess all the raw data into the inputs necessary to run GARPOS.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from es_sfgtools.processing.pipeline import DataHandler\n",
    "from es_sfgtools.utils.archive_pull import (\n",
    "    list_campaign_files_by_type\n",
    "    )\n",
    "\n",
    "from es_sfgtools.utils.loggers import BaseLogger\n",
    "from sfg_metadata import META_DATA,GEOLAB_CATALOG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm required environment variables are set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/gottlieb/miniconda3/envs/seafloor_geodesy_mac/lib'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this must be set correctly for GO executables to translate novatel to rinex\n",
    "\n",
    "#Linux\n",
    "#!echo $LD_LIBRARY_PATH\n",
    "\n",
    "#Mac\n",
    "os.environ['DYLD_LIBRARY_PATH'] = \"/Users/gottlieb/miniconda3/envs/seafloor_geodesy_mac/lib\"\n",
    "os.getenv('DYLD_LIBRARY_PATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gottlieb/.PRIDE_PPPAR_BIN/pdp3\n"
     ]
    }
   ],
   "source": [
    "# this confirms PRIDE-PPPAR is in the PATH\n",
    "!which pdp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Initial Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Browse available surveys from the community archive and select target\n",
    "- Locate the survey of interest in https://gage-data.earthscope.org/archive/seafloor, and note the `network`, `station`, and `survey` names, which will be input in the cell below.  Leave vessel_type as SV3 unless you know you are working with older SV2 data.\n",
    "- In order to use this notebook to process new surveys, the data must first be submitted and made available from the community archive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building directory structure for alaska-shumagins IVB1 2022_A_1049\n",
      "No date range set for alaska-shumagins, IVB1, 2022_A_1049\n",
      "Building TileDB arrays for IVB1\n",
      "Changed working station to alaska-shumagins IVB1\n"
     ]
    }
   ],
   "source": [
    "# Input survey parameters\n",
    "network='alaska-shumagins'\n",
    "site='IVB1'\n",
    "#campaign='2024_A_1126'\n",
    "campaign='2022_A_1049'\n",
    "vessel_type = 'SV3'\n",
    "\n",
    "# Set data directory path for local environment\n",
    "data_dir = Path(f\"{os.path.expanduser('~/data/sfg')}\")\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "#### USE THE FOLLOWING DEFAULTS UNLESS DESIRED####\n",
    "data_handler = DataHandler(directory=data_dir)\n",
    "data_handler.change_working_station(network=network, station=site, campaign=campaign)\n",
    "BaseLogger.set_dir(data_handler.station_log_dir)\n",
    "\n",
    "if vessel_type == 'SV3':\n",
    "    pipeline, config = data_handler.get_pipeline_sv3()\n",
    "elif vessel_type == 'SV2':\n",
    "    pipeline, config = data_handler.get_pipeline_sv2()\n",
    "else:\n",
    "    raise ValueError(f\"Vessel type {vessel_type} not recognized\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Inventory available data and its location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating catalog with remote paths of available data for alaska-shumagins IVB1 2022_A_1049\n",
      "Listing raw campaign files from url https://data.earthscope.org/archive/seafloor/alaska-shumagins/2022/IVB1/2022_A_1049/raw\n",
      "Found under https://data.earthscope.org/archive/seafloor/alaska-shumagins/2022/IVB1/2022_A_1049/raw:\n",
      "    120 NOV000 file(s)\n",
      "    50 NOV770 file(s)\n",
      "    8 DFOP00 file(s)\n",
      "Listing metadata campaign files from url https://data.earthscope.org/archive/seafloor/alaska-shumagins/2022/IVB1/2022_A_1049/metadata\n",
      "Found under https://data.earthscope.org/archive/seafloor/alaska-shumagins/2022/IVB1/2022_A_1049/metadata:\n",
      "    1 master file(s)\n",
      "    1 lever_arms file(s)\n",
      "    2 ctd file(s)\n",
      "31 files not recognized and skipped\n",
      "181 files already exist in the catalog\n",
      "Added 0 out of 181 files to the catalog\n"
     ]
    }
   ],
   "source": [
    "data_handler.update_catalog_from_archive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local data directory contains the following:\n",
      "    ctd: 1\n",
      "    svp: 1\n"
     ]
    }
   ],
   "source": [
    "# See what files exist locally\n",
    "data_type_counts = data_handler.get_dtype_counts()\n",
    "print(f\"Local data directory contains the following:\")\n",
    "for item in data_type_counts.items():\n",
    "    print(f\"    {item[0]}: {item[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Pull data from remote archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select files types for downloading\n",
    "Observable file types depend on whether data was collected with an SV2 or SV3 waveglider.  \n",
    "\n",
    "![Alt text](garpos_flow.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the files by type\n",
    "# data_handler.download_data(file_type='sonardyne', show_details=False)\n",
    "# data_handler.download_data(file_type='novatel', show_details=False)\n",
    "#data_handler.download_data(file_types='master')\n",
    "data_handler.download_data(file_types='seabird')\n",
    "# data_handler.download_data(file_type='leverarm', show_details=False)\n",
    "\n",
    "#data_handler.download_data(file_types='dfop00')\n",
    "#data_handler.download_data(file_types='novatel770')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from es_sfgtools.processing.operations.site_ops import (ctd_to_soundvelocity, CTDfile_to_svp, seabird_to_soundvelocity)\n",
    "ctd_path = \"/Users/gottlieb/data/sfg/alaska-shumagins/SEM1/2022_A_1049/raw/skq201811s_ctd001svpavg.cnv\"\n",
    "seabird_to_soundvelocity(ctd_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4. Parse/Process raw data to processing input schemas\n",
    "\n",
    "- 4.1 Parse acoustic observations into AcousticDataFrames\n",
    "- 4.2 Parse IMU observations into IMUDataFrames\n",
    "- 4.3 Process GNSS observables to generate PositionDataFrames\n",
    "    - Parse RANGE-A novatel messages, build RINEX files\n",
    "    - Run PRIDE-PPP-AR on RINEX, generate Kin files\n",
    "    - Parse Kin files into PositionDataFrames\n",
    "- 4.4 Parse metadata files into SiteConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Process and read DFOP00 files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config.dfop00_config.override=True\n",
    "#config.dfop00_config.show_details=True\n",
    "#pipeline.config = config\n",
    "pipeline.process_dfop00()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipeline.pre_process_novatel()### 4.3 Take all GNSS parent files and generate GNSS df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#config.novatel_config.override=True\n",
    "#pipeline.config = config\n",
    "pipeline.pre_process_novatel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.rinex_config.n_processes=2\n",
    "config.rinex_config.override=True\n",
    "pipeline.config = config\n",
    "pipeline.get_rinex_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config.rinex_config.override=True\n",
    "pipeline.config = config   \n",
    "pipeline.process_rinex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.process_kin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.update_shotdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seafloor_geodesy_mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
