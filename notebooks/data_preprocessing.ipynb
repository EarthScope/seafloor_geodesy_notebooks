{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "This notebook runs a user through the steps to select a survey and preprocess all the raw data into the inputs necessary to run GARPOS.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from es_sfgtools.pipeline import DataHandler,DATA_TYPE,FILE_TYPE,DataCatalog\n",
    "from es_sfgtools.utils.archive_pull import (\n",
    "    list_survey_files\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Initial Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Browse available surveys from the community archive and select target\n",
    "- Locate the survey of interest in https://gage-data.earthscope.org/archive/seafloor, and note the `network`, `station`, and `survey` names, which will be input in the cell below.\n",
    "- In order to use this notebook to process new surveys, the data must first be submitted and made available from the community archive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network='aleutian'\n",
    "site='IVB1'\n",
    "survey='2018_A_SFG1'\n",
    "\n",
    "#### USE THE FOLLOWING DEFAULTS UNLESS DESIRED####\n",
    "\n",
    "# Set data directory\n",
    "data_dir = Path(f\"{os.getcwd()}/data/{network}_{site}_{survey}\")\n",
    "\n",
    "# Set Logger Location\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    #format=\"{asctime} - {levelname} - {message}\",\n",
    "                    format=\"{message}\",\n",
    "                    style=\"{\",\n",
    "                    datefmt=\"%Y-%m-%d %H:%M:%S\")\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Initialize the data_handler\n",
    "data_handler = DataHandler(working_dir=data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Inventory available data and its location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of files available from remote archive\n",
    "#TODO: implement options for raw vs intermediate vs processed \n",
    "remote_filepaths = list_survey_files(network=network, station=site, survey=survey, show_details=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what files exist locally\n",
    "data_type_counts = data_handler.get_local_counts()\n",
    "logger.info(f\"Local data directory contains the following:\")\n",
    "for item in data_type_counts.items():\n",
    "    logger.info(f\"    {item[0]}: {item[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Pull data from remote archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add found remote files to the local catalog.  Note this builds an inventory, but does not do the downloading until a later step.\n",
    "# TODO: Detail counts of files local vs only remote\n",
    "data_handler.add_campaign_data(network=network, station=site, survey=survey, remote_filepaths=remote_filepaths)\n",
    "data_type_counts = data_handler.get_dtype_counts()\n",
    "logger.info(f\"Catalog now contains the following:\")\n",
    "for item in data_type_counts.items():\n",
    "    logger.info(f\"    {item[0]}: {item[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select files types for downloading\n",
    "Observable file types depend on whether data was collected with an SV2 or SV3 waveglider.  \n",
    "\n",
    "![Alt text](garpos_flow.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the files by type\n",
    "data_handler.download_campaign_data(network=network, station=site, survey=survey, file_type='sonardyne', show_details=False)\n",
    "# data_handler.download_campaign_data(network=network, station=site, survey=survey, file_type='novatel', show_details=True)\n",
    "# data_handler.download_campaign_data(network=network, station=site, survey=survey, file_type='master', show_details=False)\n",
    "# data_handler.download_campaign_data(network=network, station=site, survey=survey, file_type='svpavg', show_details=False)\n",
    "#data_handler.download_campaign_data(network=network, station=site, survey=survey, file_type='leverarm', show_details=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4. Parse/Process raw data to processing input schemas\n",
    "\n",
    "- 4.1 Parse acoustic observations into AcousticDataFrames\n",
    "- 4.2 Parse IMU observations into IMUDataFrames\n",
    "- 4.3 Process GNSS observables to generate PositionDataFrames\n",
    "    - Parse RANGE-A novatel messages, build RINEX files\n",
    "    - Run PRIDE-PPP-AR on RINEX, generate Kin files\n",
    "    - Parse Kin files into PositionDataFrames\n",
    "- 4.4 Parse metadata files into SiteConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Take all acoustic parent files and generate acoustic df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.process_acoustic_data(network=network, station=site, survey=survey, override=False, show_details=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Take all IMU parent files and generate IMU df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.process_imu_data(network=network, station=site, survey=survey, override=False, show_details=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Take all GNSS parent files and generate GNSS df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.process_rinex(network=network, station=site, survey=survey, override=False, show_details=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.process_gnss_data_kin(network=network, station=site, survey=survey, override=False, show_details=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.process_gnss_data(network=network, station=site, survey=survey,  override=False, show_details=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Take all site parent files and generate the site configuration data, which includes ATD offset, sound-velocity DF, and transponder info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.process_siteconfig(network=network, station=site, survey=survey, show_details=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5. Build ShotDataFrame\n",
    "- Combine the AcousticDataFrame, ImuDataFrame, and PositionDataFrame into a single ShotDataFrame, interpolating the IMU and Position data to match the 15s sample interval in the Acoustic Data.  \n",
    "- Store this ShotDataFrame as csv or tab-delimited ascii.\n",
    "- If ShotDataFrame csv exists, can skip and load from csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "es_sfgtools_dev",
   "language": "python",
   "name": "es_sfgtools_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
