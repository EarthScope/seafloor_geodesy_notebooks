{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "This notebook runs a user through the steps to select a survey and preprocess all the raw data into the inputs necessary to run GARPOS.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from es_sfgtools.pipeline import DataHandler\n",
    "from es_sfgtools.utils.archive_pull import (\n",
    "    list_survey_files\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Initial Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Browse available surveys from the community archive and select target\n",
    "- Locate the survey of interest in https://gage-data.earthscope.org/archive/seafloor, and note the `network`, `station`, and `survey` names, which will be input in the cell below.\n",
    "- In order to use this notebook to process new surveys, the data must first be submitted and made available from the community archive "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Inventory available data and its location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network='aleutian'\n",
    "site='SPT1'\n",
    "survey='2020_A_UOH1'\n",
    "#site='SEM1'\n",
    "#survey='2022_A_1049'\n",
    "\n",
    "#### USE THE FOLLOWING DEFAULTS UNLESS DESIRED####\n",
    "\n",
    "# Set data directory\n",
    "data_dir = Path(f\"{os.getcwd()}/data\")\n",
    "\n",
    "data_handler = DataHandler(network=network, station=site, survey=survey, data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of files available from remote archive\n",
    "#TODO: implement options for raw vs intermediate vs processed \n",
    "remote_filepaths = list_survey_files(network=network, station=site, survey=survey, show_details=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what files exist locally\n",
    "data_type_counts = data_handler.get_dtype_counts()\n",
    "print(f\"Local data directory contains the following:\")\n",
    "for item in data_type_counts.items():\n",
    "    print(f\"    {item[0]}: {item[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Pull data from remote archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add found remote files to the local catalog.  Note this builds an inventory, \n",
    "#but does not do the downloading until a later step.\n",
    "# TODO: Detail counts of files local vs only remote\n",
    "data_handler.add_data_remote(remote_filepaths=remote_filepaths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select files types for downloading\n",
    "Observable file types depend on whether data was collected with an SV2 or SV3 waveglider.  \n",
    "\n",
    "![Alt text](garpos_flow.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the files by type\n",
    "data_handler.download_data(file_type='sonardyne', show_details=False)\n",
    "data_handler.download_data(file_type='novatel', show_details=False)\n",
    "data_handler.download_data(file_type='master', show_details=False)\n",
    "data_handler.download_data(file_type='svpavg', show_details=False)\n",
    "data_handler.download_data(file_type='leverarm', show_details=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4. Parse/Process raw data to processing input schemas\n",
    "\n",
    "- 4.1 Parse acoustic observations into AcousticDataFrames\n",
    "- 4.2 Parse IMU observations into IMUDataFrames\n",
    "- 4.3 Process GNSS observables to generate PositionDataFrames\n",
    "    - Parse RANGE-A novatel messages, build RINEX files\n",
    "    - Run PRIDE-PPP-AR on RINEX, generate Kin files\n",
    "    - Parse Kin files into PositionDataFrames\n",
    "- 4.4 Parse metadata files into SiteConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Take all acoustic parent files and generate acoustic df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.process_acoustic_data(override=False, show_details=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Take all IMU parent files and generate IMU df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.process_imu_data(override=False, show_details=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Take all GNSS parent files and generate GNSS df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.process_rinex(override=False, show_details=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.process_gnss_data_kin(override=False, show_details=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.process_gnss_data(override=False, show_details=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Take all site parent files and generate the site configuration data, which includes ATD offset, sound-velocity DF, and transponder info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.process_siteconfig(override=False, show_details=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.process_atdoffset(override=False, show_details=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.process_svp(override=False, show_details=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5. Build ShotDataFrame\n",
    "- Combine the AcousticDataFrame, ImuDataFrame, and PositionDataFrame into a single ShotDataFrame, interpolating the IMU and Position data to match the 15s sample interval in the Acoustic Data.  \n",
    "- Store this ShotDataFrame as csv or tab-delimited ascii.\n",
    "- If ShotDataFrame csv exists, can skip and load from csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge position dataframes and adjust time windows based on waveglider position plots\n",
    "# def merge_position_dataframes(data_handler):\n",
    "#     paths = data_handler.catalog_data[data_handler.catalog_data['type']==\"gnss\"][\"local_location\"].dropna()\n",
    "#     merged_positions = pd.concat([pd.read_csv(path) for path in paths])\n",
    "#     merged_positions['seconds'] = merged_positions['modified_julian_date'] * 86400 + merged_positions['second_of_day']\n",
    "#     return merged_positions.set_index('seconds')\n",
    "# merged_positions = merge_position_dataframes(data_handler)\n",
    "# merged_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_positions['seconds'] = merged_positions['modified_julian_date'] * 86400 + merged_positions['second_of_day']\n",
    "#merged_positions2 = merged_positions.set_index(['modified_julian_date','second_of_day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy import stats\n",
    "# import numpy as np\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# def remove_outliers(positions, threshold=3):\n",
    "#     z_lat = np.abs(stats.zscore(positions['latitude']))\n",
    "#     outliers_lat = positions[z_lat > threshold]\n",
    "#     cleaned_positions = positions.drop(outliers_lat.index)\n",
    "#     print(outliers_lat)\n",
    "#     z_long = np.abs(stats.zscore(cleaned_positions['longitude']))\n",
    "#     outliers_long = cleaned_positions[z_long > threshold]\n",
    "#     print(outliers_long)\n",
    "#     return cleaned_positions.drop(outliers_long.index)\n",
    "\n",
    "\n",
    "# def plot_llh(positions):\n",
    "    \n",
    "#     cleaned_positions = remove_outliers(positions, threshold=1)\n",
    "#     # Create a figure with two subplots\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "#     # Plot lines between antenna positions\n",
    "#     ax.scatter(\n",
    "#         cleaned_positions[\"longitude\"],\n",
    "#         cleaned_positions[\"latitude\"],\n",
    "#         color=\"green\",\n",
    "#         marker=\"o\",\n",
    "#         linewidths=0.005,\n",
    "#     )\n",
    "\n",
    "#     # # Plot transponder positions\n",
    "#     # for transponder in garpos_input.site.transponders:\n",
    "#     #     ax_enu.scatter(\n",
    "#     #         transponder.position_enu.east,\n",
    "#     #         transponder.position_enu.north,\n",
    "#     #         label=transponder.id,\n",
    "#     #         marker=\"x\",\n",
    "#     #         color=\"red\",\n",
    "#     #         linewidths=5,\n",
    "#     #     )\n",
    "\n",
    "#     # # Plot site center enu\n",
    "#     # ax_enu.scatter(\n",
    "#     #     garpos_input.site.center_enu.east,\n",
    "#     #     garpos_input.site.center_enu.north,\n",
    "#     #     label=\"Center\",\n",
    "#     #     marker=\"x\",\n",
    "#     #     color=\"blue\",\n",
    "#     #     linewidths=5,\n",
    "#     # )\n",
    "#     ax.set_xlabel(\"Longitude\")\n",
    "#     ax.set_ylabel(\"Latitude\")\n",
    "#     ax.set_title(\"Transponder and Antenna Positions\")\n",
    "#     ax.grid(True)\n",
    "\n",
    "# plot_llh(merged_positions2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "es_sfgtools_dev",
   "language": "python",
   "name": "es_sfgtools_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
