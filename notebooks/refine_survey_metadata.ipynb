{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refining survey metadata using waveglider positions\n",
    "This notebook helps a user refine the start and stop times of different surveys patterns using existing survey metadata. If no survey metadata exists, please use the `generate_survey_metadata` notebook instead.\n",
    "***\n",
    "## 1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import tiledb\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt, colors as mcolors, cm, dates as mdates\n",
    "from typing import List\n",
    "\n",
    "# ES-SFGTools imports\n",
    "from es_sfgtools.processing.pipeline import DataHandler\n",
    "from es_sfgtools.utils.archive_pull import list_campaign_files\n",
    "from es_sfgtools.utils.metadata.site import import_site, TopLevelSiteGroups, SubLevelSiteGroups\n",
    "from es_sfgtools.utils.metadata.campaign import Survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 2. Data Preparation and Archive Retrieval\n",
    "\n",
    "### 2.1 Set survey parameters\n",
    "\n",
    "1. Input survey releated metadata including...\n",
    "* **network name** - name of network the site belongs to\n",
    "* **site name** - 4 character site name\n",
    "* **campaign name** (e.g YYYY_A_VESS) - check the metadata file to ensure you have the correct campaign name\n",
    "* **vessel type** (e.g SV2 or SV3) - this type will determine which pipeline to run\n",
    "\n",
    "2. Set the local data directory you wish to use to store campaign files, logs, and tileDB arrays. It will be created if it does not yet exist. Under this directory, a `campaign_plots` directory will also be created for any plots we generate in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input survey parameters\n",
    "network = 'cascadia-gorda'\n",
    "site = 'NCC1'\n",
    "campaign_name = '2024_A_1126'   \n",
    "vessel_type = 'SV3'             # SV2 or SV3 is supported\n",
    "\n",
    "# Set data directory path for local environment\n",
    "directory = './data/sfg'\n",
    "\n",
    "# ------------------------------------- #\n",
    "# This will create the data directory if it does not exist\n",
    "data_dir = Path(f\"{os.path.expanduser(directory)}\")\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Add local survey plots directory\n",
    "plots_dir = directory + '/campaign_plots'\n",
    "plots_dir = Path(f\"{os.path.expanduser(plots_dir)}\")\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "print(f\"Plots directory: {plots_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Load and inspect existing metadata\n",
    "\n",
    "Please enter the location of your **metadata file** to import data. Campaign start and end dates will be saved for setting up the `DataHandler` class in the next step.\n",
    "\n",
    "*If no campaign is displayed, ensure you have the correct campaign name in the cell above and re-run if neccessary. If no campaign exists in the metadata, use the **generate_survey_metadata** notebook instead.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the path to the metadata file\n",
    "metadata_uri = \"./site_vessels/NCC1.2025-03-20.json\"    \n",
    "\n",
    "# ---------------------------------- #\n",
    "# Load and inspect existing metadata\n",
    "print(f\"Loading site metadata from {metadata_uri} ... \\n\")\n",
    "site_metadata = import_site(metadata_uri)\n",
    "\n",
    "# Get the campaign set above and add the surveys to a list we will use later\n",
    "print(f\"Searching for campaign: {campaign_name} ... \\n\")\n",
    "surveys = []\n",
    "for campaign in site_metadata.campaigns:\n",
    "    if campaign.name == campaign_name:\n",
    "        start = campaign.start\n",
    "        end = campaign.end\n",
    "        print(f\"  Campaign: {campaign.name} \\n   Start: {start} \\n    End: {end}\\n\")\n",
    "\n",
    "        for survey in campaign.surveys:\n",
    "            print(f\"  Survey: {survey.id} \\n   Start: {survey.start} \\n    End: {survey.end}\")\n",
    "            surveys.append(survey)\n",
    "\n",
    "        break\n",
    "\n",
    "if not surveys:\n",
    "    print(f\"No surveys found for campaign: {campaign_name} \\n, please use generate_survey_metadata notebook to create surveys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Set up the data handler class with our survey parameters\n",
    "\n",
    "This will set up a `DataHandler` class using our data directory and site related information we set above. By doing this, the data handler will populate our data directory with the necessary folders and tileDB arrays. This cell also grab the correct pipeline for the vessel type specified (SV2/SV3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the DataHandler class\n",
    "data_handler = DataHandler(directory=data_dir) \n",
    "\n",
    "# Set the survey parameters\n",
    "data_handler.change_working_station(network=network, \n",
    "                                    station=site, \n",
    "                                    campaign=campaign_name, \n",
    "                                    start_date=start.date(),    # Start date of the campaign (time not accepted)\n",
    "                                    end_date=end.date())        # End date of the campaign (time not accepted)\n",
    "\n",
    "if vessel_type == 'SV3':\n",
    "    pipeline, config = data_handler.get_pipeline_sv3()\n",
    "elif vessel_type == 'SV2':\n",
    "    pipeline, config = data_handler.get_pipeline_sv2()\n",
    "else:\n",
    "    raise ValueError(f\"Vessel type {vessel_type} not recognized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Get the acoustic (DFOP00) files from the EarthScope archive\n",
    "\n",
    "This will go to the EarthScope archive and list files for the specific campaign. The `DataHandler` class will then add this remote file list to the catalog stored within our data directory set above. It will then download only the DFOP00 files to our data directory. \n",
    "\n",
    "*If you have already run this cell prior, it will likely not need to download the files again.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DFOP00 file list from the archive\n",
    "remote_filepaths = list_campaign_files(network=network, station=site, campaign=campaign_name)\n",
    "\n",
    "# Add the data to the data handler\n",
    "data_handler.add_data_remote(remote_filepaths=remote_filepaths)\n",
    "\n",
    "# Download the dfop00 files, if not already downloaded (override=False)\n",
    "data_handler.download_data(file_types='dfop00', override=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Read DFOP00 files into shotdata array\n",
    "\n",
    "Using the SV pipeline chosen above, we will create an array from the DFOP00 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read DFOP00 files into shotdata array\n",
    "config.dfop00_config.override=True          # Flag to override existing data\n",
    "pipeline.config = config\n",
    "pipeline.process_dfop00()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Convert data from array into a dataframe\n",
    "\n",
    "Using the shotdata we just stored in a tileDB array, we will create a dataframe to use in the notebook going forward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the shotdata array URI\n",
    "shotdata_uri = f\"{directory}/{network}/{site}/TileDB/shotdata_db.tdb\"\n",
    "\n",
    "#  Get the start and end dates of the campaign\n",
    "campaign_start = data_handler.date_range[0]\n",
    "campaign_end = data_handler.date_range[1]\n",
    "\n",
    "# Read data from the TileDB array\n",
    "print(f\"Reading dataframe from {shotdata_uri} for {campaign_start} to {campaign_end}\")\n",
    "with tiledb.open(shotdata_uri, mode=\"r\") as array:\n",
    "    shot_data_dataframe = array.df[slice(np.datetime64(campaign_start), np.datetime64(campaign_end)),:]\n",
    "\n",
    "# Show preview of the data\n",
    "shot_data_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 3. Plot Waveglider Locations\n",
    "\n",
    "Now that we have our data ready, we can begin plotting waveglider locations and refining our surveys.\n",
    "\n",
    "### 3.1 Set plotting functions\n",
    "We will use these 2 plotting functions to refine our surveys below. Run the next cell to set these functions. If you wish to change how the plots look, this is where you would be able to do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_en(df, surveys: List[Survey] = [], save_as: str = None):\n",
    "    \"\"\"\n",
    "    Plots the East and North positions over time for a given dataset, with survey periods highlighted.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the survey data with columns like 'triggerTime', 'east0', and 'north0'.\n",
    "    - surveys: List of survey objects, each containing 'start', 'end', 'type', and optional 'notes'.\n",
    "    - save_as: Optional string specifying the filename to save the plot. If None, the plot is not saved.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a figure with two subplots (one for East, one for North)\n",
    "    fig, axs = plt.subplots(nrows=2, figsize=(16,10))  \n",
    "\n",
    "    # Set x and y axis labels\n",
    "    axs[0].set_ylabel(\"East (m)\")\n",
    "    axs[1].set_ylabel(\"North (m)\")\n",
    "\n",
    "    # Scatter plot for East positions\n",
    "    sc0 = axs[0].scatter(\n",
    "        df[\"triggerTime\"],\n",
    "        df[\"east0\"],\n",
    "        alpha=0.25\n",
    "    )\n",
    "    # Scatter plot for North positions\n",
    "    sc1 = axs[1].scatter(\n",
    "        df[\"triggerTime\"],\n",
    "        df[\"north0\"],\n",
    "        alpha=0.25\n",
    "    )\n",
    "\n",
    "    # Generate a rainbow colormap for the surveys\n",
    "    survey_colors = cm.rainbow(np.linspace(0, 1, len(surveys)))\n",
    "    # Highlight survey periods on both subplots\n",
    "    for ax in axs:\n",
    "        for i, survey in enumerate(surveys):\n",
    "            start = survey.start\n",
    "            end = survey.end\n",
    "            label = survey.type + \" \" + survey.notes if survey.notes else survey.type\n",
    "\n",
    "            # Highlight the survey period with a colored span\n",
    "            ax.axvspan(start, end, color=survey_colors[i], alpha=0.3, label=label)\n",
    "        \n",
    "        # Make ticks on occurrences of each month:\n",
    "        ax.xaxis.set_major_locator(mdates.DayLocator())\n",
    "        \n",
    "        # Format the x-axis to display dates in 'month-day' format\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "    \n",
    "    # Rotate x-axis labels 90 degrees\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "    # Add a legnend to the first subplot\n",
    "    axs[0].legend()\n",
    "\n",
    "    # Save the plot to a file if a filename is provided\n",
    "    if save_as is not None:\n",
    "        plt.savefig(save_as)\n",
    "        \n",
    "\n",
    "def plot_wg_position(df, start: datetime, end: datetime, survey: Survey = None):\n",
    "    \"\"\"\n",
    "    Plots the antenna position (East vs. North) for a specific survey within a given time range.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the survey data with columns like 'triggerTime', 'east0', and 'north0'.\n",
    "    - survey_name: Name of the survey (string).\n",
    "    - survey_type: Type of the survey (string).\n",
    "    - start: Start time of the survey (datetime object).\n",
    "    - end: End time of the survey (datetime object).\n",
    "    \"\"\"\n",
    "    # Filter the DataFrame for the specified time range\n",
    "    temp_df = df[df['triggerTime']>=start]\n",
    "    temp_df = temp_df[df['triggerTime']<=end]\n",
    "\n",
    "    # Create a figure and axis for the plot\n",
    "    fig, ax = plt.subplots(figsize=(16,10))\n",
    "\n",
    "    # Set the title of the plot and the filename for saving the figure\n",
    "    if survey is not None:\n",
    "        survey_name = survey.id\n",
    "        survey_type = survey.type\n",
    "        title = f\"{survey_name} {survey_type} from {start.isoformat()} to {end.isoformat()}\"\n",
    "        save_as = f\"{plots_dir}/{survey_name}_{survey_type}.png\"\n",
    "        fig.suptitle(title)\n",
    "    else:\n",
    "        title = f\"Survey from {start.isoformat()} to {end.isoformat()}\"\n",
    "        save_as = f\"{plots_dir}/survey_{start.isoformat()}_{end.isoformat()}.png\"\n",
    "        fig.suptitle(title)\n",
    "\n",
    "    # Set the x and y axis labels\n",
    "    ax.set_xlabel(\"East (m)\")\n",
    "    ax.set_ylabel(\"North (m)\")\n",
    "\n",
    "    # Optional: Plot the origin point (?)\n",
    "    #ax.scatter(0, 0, label=\"Origin\", color=\"magenta\",s=100)\n",
    "\n",
    "    # Convert trigger times to timestamps and scale them for colormap normalization\n",
    "    colormap_times = temp_df[\"triggerTime\"].apply(lambda x:x.timestamp()).to_numpy()\n",
    "    colormap_times_scaled = (colormap_times - colormap_times.min())/3600\n",
    "\n",
    "    # Normalize the colormap to the range of scaled times\n",
    "    norm = mcolors.Normalize(\n",
    "        vmin=0,\n",
    "        vmax=(colormap_times.max() - colormap_times.min()) / 3600,\n",
    "    )\n",
    "\n",
    "    # Scatter plot of East vs. North positions, colored by time\n",
    "    sc = ax.scatter(\n",
    "        temp_df[\"east0\"],\n",
    "        temp_df[\"north0\"],\n",
    "        c=colormap_times_scaled,\n",
    "        cmap=\"viridis\",\n",
    "        label=\"Antenna Position\",\n",
    "        norm=norm,\n",
    "        alpha=0.25\n",
    "    )\n",
    "\n",
    "    # Add a colorbar to indicate time in hours\n",
    "    cbar = plt.colorbar(sc,label=\"Time (hr)\",norm=norm)\n",
    "\n",
    "    # Add a legend to the plot\n",
    "    ax.legend()\n",
    "\n",
    "    # Save the plot to a file\n",
    "    plt.savefig(save_as)\n",
    "\n",
    "    # Print the start and end times of the filtered data\n",
    "    print(temp_df.triggerTime.iloc[0].isoformat(), temp_df.triggerTime.iloc[-1].isoformat())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 View the surveys available\n",
    "\n",
    "If you wish to review the surveys available, run the next cell. You will need to survey IDs to plot individual surveys. The typical ID is in the format `CAMPAIGN_NAME_INTERVAL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {len(surveys)} surveys in the campaign {campaign_name} \\n\")\n",
    "for survey in surveys:\n",
    "    print(survey.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Plot the full campaign with all surveys\n",
    "\n",
    "This next cell takes the start and end date of the shot data dataframe and plots the east and north positions over time as well as the waveglider map positions. If surveys already exist within the metadata, they are shown and labels on the east/north plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust to remove any junk data at beginning or end if needed\n",
    "start = shot_data_dataframe.triggerTime.iloc[0] + timedelta(hours=0, minutes=0)\n",
    "end = shot_data_dataframe.triggerTime.iloc[-1] - timedelta(hours=0, minutes=0)\n",
    "\n",
    "# Filter the DataFrame for the specified time range\n",
    "temp_df = shot_data_dataframe[shot_data_dataframe['triggerTime'] >= start]\n",
    "temp_df = temp_df[shot_data_dataframe['triggerTime'] <= end]\n",
    "\n",
    "# Plot the East and North positions over time\n",
    "plot_en(temp_df, surveys)\n",
    "\n",
    "# Plot the waveglider position\n",
    "plot_wg_position(shot_data_dataframe, start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4. Refine surveys\n",
    "In this section we will begin refining our surveys. It may be run through multiple times as needed. \n",
    "\n",
    "### 4.1 Plot individual survey\n",
    "\n",
    "Now that we have plotted the full campaign, lets narrow down on an individual survey. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the the survey ID to plot - typically in the format of `campaignName_interval`, \n",
    "# for example `2024_A_1126_1`. Check the surveys above for the correct ID.\n",
    "survey_id = \"\"\n",
    "\n",
    "# ----------------------------- #\n",
    "# Get the correct survey object\n",
    "survey = next((survey for survey in surveys if survey.id == survey_id), None)\n",
    "\n",
    "if not survey:\n",
    "    raise ValueError(f\"Survey {survey_id} not found in the list of surveys.\")\n",
    "else:\n",
    "    print(f\"Plotting survey {survey_id} ...\")\n",
    "\n",
    "# Plot the East and North positions over time for the selected survey\n",
    "plot_en(temp_df, [survey])\n",
    "\n",
    "# Plot the waveglider position for the selected survey\n",
    "plot_wg_position(df=shot_data_dataframe, start=survey.start, end=survey.end, survey=survey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Refine the original survey\n",
    "\n",
    "In this next cell we have the option or add or delete time from the start and end times of the survey. Change the hours and minutes of the `timedelta` function for the `new_start` and `new_end` variables. The default is to add to the start time and subtract from the end time. If you wish to do differently, remember to change those +/-'s. \n",
    "\n",
    "Re-run this cell multiple times and view the plots to refine the survey times to your desired start and end times, then move on to the next cell to update the original metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the hours and minutes for the survey you want to refine the times of.\n",
    "new_start = survey.start + timedelta(hours=0, minutes=0)\n",
    "new_end = survey.end - timedelta(hours=0, minutes=0)\n",
    "\n",
    "# -------------------- #\n",
    "# View the plots associated with the new start and end times\n",
    "plot_en(temp_df, [survey])\n",
    "plot_wg_position(df=shot_data_dataframe, start=new_start, end=new_end, survey=survey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Update original survey metadata\n",
    "\n",
    "Running this next cell with update the survey metadata you refined above that we set in the beginning using the site metadata file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the survey metadata, ID is required, updating start and end times\n",
    "update_survey_data = {\"id\": survey.id, \"start\": new_start.isoformat(), \"end\": new_end.isoformat()}\n",
    "\n",
    "# Update the survey metadata in the site metadata\n",
    "site_metadata.run_sub_component(component_type=TopLevelSiteGroups.CAMPAIGNS, component_name=campaign_name,\n",
    "                            sub_component_type=SubLevelSiteGroups.SURVEYS, sub_component_metadata=update_survey_data,\n",
    "                            update=True)\n",
    "\n",
    "# Save the updated site metadata to a new file\n",
    "plot_en(temp_df, surveys, save_as=f\"{site}_{campaign_name}_surveys.png\")\n",
    "\n",
    "# Reload the surveys to update the list with the refined times\n",
    "surveys = []\n",
    "for campaign in site_metadata.campaigns:\n",
    "    if campaign.name == campaign_name:\n",
    "        for survey in campaign.surveys:\n",
    "            surveys.append(survey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Refine another survey\n",
    "\n",
    "If you haven't finished refining the surveys you want to refine, go back to 4.1, input a new survey ID and run through section 4 again. \n",
    "\n",
    "If you have finished, move on to section 5.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 5. Finalize and Export Survey Data\n",
    " \n",
    "### 5.1 View all survey maps\n",
    "\n",
    "This cell will go through each survey and plot the waveglider positions for each one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for individual_survey in surveys:\n",
    "    plot_wg_position(df=shot_data_dataframe, start=individual_survey.start, end=individual_survey.end, survey=individual_survey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Export updated site metadata to file\n",
    "\n",
    "This will export the new metadata to a file in the current directory. File name format is `[site].[refined_surveys].[date].json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SITE_4_CHAR_ID = site # 4 char site ID\n",
    "\n",
    "if not SITE_4_CHAR_ID:\n",
    "    raise ValueError(\"Please enter a 4 char site ID\")\n",
    "\n",
    "# Export site metadata to a json file\n",
    "# Add date to the file name\n",
    "date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "file_path = f\"./{SITE_4_CHAR_ID + '.refined_surveys.' + date}.json\"          # Export file path you wish to store\n",
    "site_metadata.export_site(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seafloor_geodesy_mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
