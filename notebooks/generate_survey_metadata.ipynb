{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating survey metadata using waveglider positions\n",
    "\n",
    "This notebook helps a user locate the start and stop times of different surveys patterns when no survey metadata exists. If survey metadata already exists and you wish to refine start and stop times of existing metadata, please use the `refine_survey_metadata` notebook instead. \n",
    "***\n",
    "## 1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import tiledb\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt, colors as mcolors, cm, dates as mdates\n",
    "from typing import List\n",
    "\n",
    "# ES-SFGTools imports\n",
    "from es_sfgtools.processing.pipeline import DataHandler\n",
    "from es_sfgtools.utils.archive_pull import list_campaign_files\n",
    "from es_sfgtools.utils.metadata.site import import_site, TopLevelSiteGroups, SubLevelSiteGroups\n",
    "from es_sfgtools.utils.metadata.campaign import Survey, campaign_checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 2. Data Preparation and Archive Retrieval\n",
    "### 2.1 Set survey parameters\n",
    "\n",
    "1. Input survey releated metadata including...\n",
    "* **network name** - name of network the site belongs to\n",
    "* **site name** - 4 character site name\n",
    "* **campaign name** (e.g YYYY_A_VESS) - check the metadata file to ensure you have the correct campaign name\n",
    "* **vessel type** (e.g SV2 or SV3) - this type will determine which pipeline to run\n",
    "\n",
    "2. Set the local data directory you wish to use to store campaign files, logs, and tileDB arrays. It will be created if it does not yet exist. Under this directory, a `campaign_plots` directory will also be created for any plots we generate in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input survey parameters\n",
    "network = 'cascadia-gorda'\n",
    "site = 'NBR1'\n",
    "campaign_name = '2023_A_1063'   \n",
    "vessel_type = 'SV3'             # SV2 or SV3 is supported\n",
    "\n",
    "# Set data directory path for local environment\n",
    "directory = './data/sfg'\n",
    "\n",
    "# ------------------------------------- #\n",
    "# This will create the data directory if it does not exist\n",
    "data_dir = Path(f\"{os.path.expanduser(directory)}\")\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "\n",
    "# Add local survey plots directory\n",
    "plots_dir = directory + '/campaign_plots'\n",
    "plots_dir = Path(f\"{os.path.expanduser(plots_dir)}\")\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "print(f\"Plots directory: {plots_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Load and inspect existing metadata\n",
    "\n",
    "Please enter the location of your **metadata file** to import data. Campaign start and end dates will be saved for setting up the `DataHandler` class in the next step.\n",
    "\n",
    "*If a campaign and surveys already exist and you just wish to refine them, please use the **refine_survey_metadata** notebook instead.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the path to the site metadata file you want to use and update\n",
    "metadata_uri = \"./site_vessels/NBR1.2025-03-19.json\"    \n",
    "\n",
    "# ---------------------------------- #\n",
    "# Load and inspect existing metadata\n",
    "print(f\"Loading site metadata from {metadata_uri} ... \\n\")\n",
    "site_metadata = import_site(metadata_uri)\n",
    "\n",
    "campaign_check = False\n",
    "start = None\n",
    "end = None\n",
    "\n",
    "# Check if the campaign already exists in the site metadata\n",
    "surveys = []\n",
    "for campaign in site_metadata.campaigns:\n",
    "    if campaign.name == campaign_name:\n",
    "        campaign_check = True\n",
    "        start = campaign.start\n",
    "        end = campaign.end\n",
    "        print(f\"  Campaign: {campaign.name} \\n   Start: {start} \\n    End: {end}\\n\")\n",
    "\n",
    "        for survey in campaign.surveys:\n",
    "            print(f\"  Survey: {survey.id} \\n   Start: {survey.start} \\n    End: {survey.end}\")\n",
    "            surveys.append(survey)\n",
    "        \n",
    "        if len(surveys) > 0:\n",
    "            print(f\"Found {len(surveys)} surveys in {campaign.name} campaign. If you wish to refine these surveys instead, please use the refine_survey_metadata notebook.\")\n",
    "\n",
    "        break\n",
    "\n",
    "if not campaign_check:\n",
    "    print(f\"Campaign {campaign_name} not found in site metadata. Please create the campaign metadata below.\")\n",
    "else: \n",
    "    print(f\"Campaign {campaign_name} found in site metadata. Proceed to create more surveys below.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Set up the data handler class with our survey parameters\n",
    "\n",
    "This will set up a `DataHandler` class using our data directory and site related information we set above. By doing this, the data handler will populate our data directory with the necessary folders and tileDB arrays. This cell also grab the correct pipeline for the vessel type specified (SV2/SV3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the DataHandler class\n",
    "data_handler = DataHandler(directory=data_dir) \n",
    "\n",
    "# Set the survey parameters\n",
    "data_handler.change_working_station(network=network, \n",
    "                                    station=site, \n",
    "                                    campaign=campaign_name) \n",
    "                                    # start_date=start.date(),    # Start date of the campaign (time not accepted)\n",
    "                                    # end_date=end.date())        # End date of the campaign (time not accepted)\n",
    "\n",
    "if vessel_type == 'SV3':\n",
    "    pipeline, config = data_handler.get_pipeline_sv3()\n",
    "elif vessel_type == 'SV2':\n",
    "    pipeline, config = data_handler.get_pipeline_sv2()\n",
    "else:\n",
    "    raise ValueError(f\"Vessel type {vessel_type} not recognized\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Get the acoustic (DFOP00) files from the EarthScope archive\n",
    "\n",
    "This will go to the EarthScope archive and list files for the specific campaign. The `DataHandler` class will then add this remote file list to the catalog stored within our data directory set above. It will then download only the DFOP00 files to our data directory. \n",
    "\n",
    "*If you have already run this cell prior, it will likely not need to download the files again.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DFOP00 file list from the archive\n",
    "remote_filepaths = list_campaign_files(network=network, station=site, campaign=campaign_name)\n",
    "\n",
    "# Add the data to the data handler\n",
    "data_handler.add_data_remote(remote_filepaths=remote_filepaths)\n",
    "\n",
    "# Download the dfop00 files, if not already downloaded (override=False)\n",
    "data_handler.download_data(file_types='dfop00', override=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Read DFOP00 files into shotdata array\n",
    "\n",
    "Using the SV pipeline chosen above, we will create an array from the DFOP00 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read DFOP00 files into shotdata array\n",
    "config.dfop00_config.override=True          # Flag to override existing data\n",
    "pipeline.config = config\n",
    "pipeline.process_dfop00()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Convert data from array into a dataframe\n",
    "\n",
    "Using the shotdata we just stored in a tileDB array, we will create a dataframe to use in the notebook going forward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the shotdata array URI\n",
    "shotdata_uri = f\"{directory}/{network}/{site}/TileDB/shotdata_db.tdb\"\n",
    "\n",
    "# Read data from the TileDB array\n",
    "with tiledb.open(shotdata_uri, mode=\"r\") as array:\n",
    "    shot_data_dataframe = array.df[:]\n",
    "\n",
    "# Show preview of the data\n",
    "shot_data_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 3.  Plot waveglider locations\n",
    "\n",
    "Now that we have our data ready, we can begin plotting waveglider locations and refining our surveys.\n",
    "\n",
    "### 3.1 Set plotting functions\n",
    "We will use these 2 plotting functions to refine our surveys below. Run the next cell to set these functions. If you wish to change how the plots look, this is where you would be able to do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_en(df, surveys: List[Survey]=[], save_as: str = None):\n",
    "    \"\"\"\n",
    "    Plots the East and North positions over time for a given dataset, with survey periods highlighted.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the survey data with columns like 'triggerTime', 'east0', and 'north0'.\n",
    "    - surveys: List of survey objects, each containing 'start', 'end', 'type', and optional 'notes'.\n",
    "    - save_as: Optional string specifying the filename to save the plot. If None, the plot is not saved.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a figure with two subplots (one for East, one for North)\n",
    "    fig, axs = plt.subplots(nrows=2, figsize=(16,10))  \n",
    "\n",
    "    # Set x and y axis labels\n",
    "    axs[0].set_ylabel(\"East (m)\")\n",
    "    axs[1].set_ylabel(\"North (m)\")\n",
    "\n",
    "    # Scatter plot for East positions\n",
    "    sc0 = axs[0].scatter(\n",
    "        df[\"triggerTime\"],\n",
    "        df[\"east0\"],\n",
    "        alpha=0.25\n",
    "    )\n",
    "    # Scatter plot for North positions\n",
    "    sc1 = axs[1].scatter(\n",
    "        df[\"triggerTime\"],\n",
    "        df[\"north0\"],\n",
    "        alpha=0.25\n",
    "    )\n",
    "\n",
    "    # Generate a rainbow colormap for the surveys\n",
    "    survey_colors = cm.rainbow(np.linspace(0, 1, len(surveys)))\n",
    "    # Highlight survey periods on both subplots\n",
    "    for ax in axs:\n",
    "        for i, survey in enumerate(surveys):\n",
    "            start = survey.start\n",
    "            end = survey.end\n",
    "            label = survey.type + \" \" + survey.notes if survey.notes else survey.type\n",
    "\n",
    "            # Highlight the survey period with a colored span\n",
    "            ax.axvspan(start, end, color=survey_colors[i], alpha=0.3, label=label)\n",
    "        \n",
    "        # Make ticks on occurrences of each month:\n",
    "        ax.xaxis.set_major_locator(mdates.DayLocator())\n",
    "        \n",
    "        # Format the x-axis to display dates in 'month-day' format\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "    \n",
    "    # Rotate x-axis labels 90 degrees\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "    # Add a legnend to the first subplot\n",
    "    axs[0].legend()\n",
    "\n",
    "    # Save the plot to a file if a filename is provided\n",
    "    if save_as is not None:\n",
    "        plt.savefig(save_as)\n",
    "        \n",
    "\n",
    "def plot_wg_position(df, start: datetime, end: datetime, survey: Survey = None):\n",
    "    \"\"\"\n",
    "    Plots the antenna position (East vs. North) for a specific survey within a given time range.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the survey data with columns like 'triggerTime', 'east0', and 'north0'.\n",
    "    - start: Start time of the survey (datetime object).\n",
    "    - end: End time of the survey (datetime object).\n",
    "    \"\"\"\n",
    "    # Filter the DataFrame for the specified time range\n",
    "    temp_df = df[df['triggerTime']>=start]\n",
    "    temp_df = temp_df[df['triggerTime']<=end]\n",
    "\n",
    "    # Create a figure and axis for the plot\n",
    "    fig, ax = plt.subplots(figsize=(16,10))\n",
    "\n",
    "    # Set the title of the plot and the filename for saving the figure\n",
    "    if survey is not None:\n",
    "        survey_name = survey.id\n",
    "        survey_type = survey.type\n",
    "        title = f\"{survey_name} {survey_type} from {start.isoformat()} to {end.isoformat()}\"\n",
    "        save_as = f\"{plots_dir}/{survey_name}_{survey_type}.png\"\n",
    "        fig.suptitle(title)\n",
    "    else:\n",
    "        title = f\"Survey from {start.isoformat()} to {end.isoformat()}\"\n",
    "        save_as = f\"{plots_dir}/survey_{start.isoformat()}_{end.isoformat()}.png\"\n",
    "        fig.suptitle(title)\n",
    "\n",
    "    # Set the x and y axis labels\n",
    "    ax.set_xlabel(\"East (m)\")\n",
    "    ax.set_ylabel(\"North (m)\")\n",
    "\n",
    "    # Optional: Plot the origin point (?)\n",
    "    #ax.scatter(0, 0, label=\"Origin\", color=\"magenta\",s=100)\n",
    "\n",
    "    # Convert trigger times to timestamps and scale them for colormap normalization\n",
    "    colormap_times = temp_df[\"triggerTime\"].apply(lambda x:x.timestamp()).to_numpy()\n",
    "    colormap_times_scaled = (colormap_times - colormap_times.min())/3600\n",
    "\n",
    "    # Normalize the colormap to the range of scaled times\n",
    "    norm = mcolors.Normalize(\n",
    "        vmin=0,\n",
    "        vmax=(colormap_times.max() - colormap_times.min()) / 3600,\n",
    "    )\n",
    "\n",
    "    # Scatter plot of East vs. North positions, colored by time\n",
    "    sc = ax.scatter(\n",
    "        temp_df[\"east0\"],\n",
    "        temp_df[\"north0\"],\n",
    "        c=colormap_times_scaled,\n",
    "        cmap=\"viridis\",\n",
    "        label=\"Antenna Position\",\n",
    "        norm=norm,\n",
    "        alpha=0.25\n",
    "    )\n",
    "\n",
    "    # Add a colorbar to indicate time in hours\n",
    "    cbar = plt.colorbar(sc,label=\"Time (hr)\",norm=norm)\n",
    "\n",
    "    # Add a legend to the plot\n",
    "    ax.legend()\n",
    "\n",
    "    # Save the plot to a file\n",
    "    plt.savefig(save_as)\n",
    "\n",
    "    # Print the start and end times of the filtered data\n",
    "    print(f\"Start Time: {temp_df.triggerTime.iloc[0].isoformat()} \\nEnd Time: {temp_df.triggerTime.iloc[-1].isoformat()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Plot & refine the full campaign\n",
    "\n",
    "This next cell plots the entire shot data dataframe as well as the waveglider map positions. To alter..\n",
    "1. Run the cell and view the full campaign via the plots below\n",
    "2. Adjust the start and end dates using the +/- `timedelta` function within the start and end date variables.\n",
    "3. Repeat as necessary to trim the campaign start and end dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust to remove any junk data at beginning or end if needed\n",
    "start = shot_data_dataframe.triggerTime.iloc[0] + timedelta(hours=0, minutes=0)\n",
    "end = shot_data_dataframe.triggerTime.iloc[-1] - timedelta(hours=0, minutes=0)\n",
    "\n",
    "# ----------------------- #\n",
    "# Filter the DataFrame for the specified time range set above\n",
    "temp_df = shot_data_dataframe[shot_data_dataframe['triggerTime'] >= start]\n",
    "temp_df = temp_df[shot_data_dataframe['triggerTime'] <= end]\n",
    " \n",
    "# Plot the East/North positions over time\n",
    "plot_en(df=temp_df)\n",
    "\n",
    "# Plot the waveglider position\n",
    "plot_wg_position(df=shot_data_dataframe, start=start, end=end)\n",
    "\n",
    "# Print total number of days in survey\n",
    "print(f\"Total number of days in campaign: {(end-start).days} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Optional: Create the campaign \n",
    "\n",
    "If the campaign we are working on does not exist in the metadata, we will need to create that first. If a campaign already exists, skip this section and start working on creating surveys. \n",
    "\n",
    "To create the campaign, make sure we have all of the required information below. `Name`, `Vessel Code`, `start` and `end` are variables we have already set above. Enter the `type` and any optional information if you know it. Run the cell and just the json output to ensure its correct. If incorrect, re-edit and rerun the cell. If correct, add the campaign to the site metadata below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign = {}\n",
    "# ----------------------- Update these values if needed ----------------------- \n",
    "\n",
    "# -- Required information for new campaign --\n",
    "campaign['name'] = campaign_name\n",
    "campaign['vesselCode'] = campaign_name[-4:]  # Extract the last 4 characters of the campaign name\n",
    "campaign['start'] = start.isoformat()         # Start date of campaign\n",
    "campaign['end'] = end.isoformat()            # End date of campaign\n",
    "\n",
    "campaign['type'] = \"\"           # type of campaign: deploy | measure \n",
    "\n",
    "# -- Optional: Enter information known about the people and vessels involved in the campaign --\n",
    "campaign['launchVesselName'] = \"\"             # launch vessel name used in campaign\n",
    "campaign['recoveryVesselName'] = \"\"           # recovery vessel name used in campaign\n",
    "campaign['principalInvestigator'] = \"\"        # PI name \n",
    "campaign['cruiseName'] = \"\"                   # Name of cruise\n",
    "campaign['technicianName'] = \"\"               # technician name\n",
    "campaign['technicianContact'] = \"\"            # technician contact information (email/phone)\n",
    "\n",
    "\n",
    "# ----------------------- Do not update code below ----------------------- \n",
    "print(json.dumps(campaign, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confirm output it correct and then run the next cell to add the campaign to the site metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------- Do not update code below -----------------------\n",
    "site_metadata.run_component(component_type=TopLevelSiteGroups.CAMPAIGNS, component_metadata=campaign, add_new=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to view the entire site metadata, you can print it out\n",
    "site_metadata.print_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "## 4. Create surveys\n",
    "In this section we will begin creating surveys. It may be run through multiple times as needed. \n",
    "\n",
    "### 4.1 Plot individual survey\n",
    "Using the campaign start and end times defined above, use the `timedelta` function to edit days, hours and mintutes to narrow down on a survey. Each time you run the cell, a new plot will be generated to show you the east and north positions as well as the waveglider map position. \n",
    "\n",
    "Be sure to update the survey interval on each subsequent survey created, otherwise you will get an error when trying to add the survey to the metadata. If a survey already existed prior to running this notebook, you may need to start with a higher number initially. Check the survey IDs in the metadata if so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the survey interval to the next number on each subsequent survey creation\n",
    "survey_interval = 1\n",
    "\n",
    "survey_start = start + timedelta(days=0, hours=1, minutes=0)\n",
    "survey_end = end - timedelta(days=6, hours=6, minutes=0)\n",
    "\n",
    "# Create a new survey object\n",
    "survey = Survey(\n",
    "    id=campaign_name + \"_\"  + str(survey_interval),\n",
    "    start=survey_start,\n",
    "    end=survey_end,\n",
    "    type=\"\",                                        # If you can identify, add the type of survey\n",
    "    benchmarkIDs=[],                                # If you can identify the benchmark IDs, add them here\n",
    "    notes=\"Visual identification\",                  # Any additional notes about the survey\n",
    ")\n",
    "\n",
    "plot_en(temp_df, [survey])\n",
    "plot_wg_position(df=shot_data_dataframe, start=survey.start, end=survey.end, survey=survey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Add the survey to our metadata\n",
    "\n",
    "Once you have narrowed down your survey and any associated metadata, run the next cell to add it to the metadata class. If you wish to create more surveys, repeat the **4.1** step above. If you want to see all surveys so far, run the 2 plot cells below in section 5 to check it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_metadata.run_sub_component(component_type=TopLevelSiteGroups.CAMPAIGNS, component_name=campaign_name,\n",
    "                            sub_component_type=SubLevelSiteGroups.SURVEYS, sub_component_metadata=survey.__dict__,\n",
    "                            add_new=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 5. Finalize and Export Survey Data\n",
    "### 5.1 Plot East/North plots with each survey shaded over top.\n",
    "\n",
    "This cell grabs all of the surveys added to the campaign metadata and plots the east/north positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys=[]\n",
    "for campaign in site_metadata.campaigns:\n",
    "    if campaign.name == campaign_name:\n",
    "        for survey in campaign.surveys:\n",
    "            surveys.append(survey)\n",
    "\n",
    "# Plot the surveys we have so far\n",
    "plot_en(temp_df, surveys, save_as=f\"{plots_dir}/{site}_{campaign_name}_surveys.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 View all survey maps\n",
    "\n",
    "Run this cell to view and save all of the survey plots created thus far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for individual_survey in surveys:\n",
    "    print(f\"Survey: {individual_survey.id}\")\n",
    "    plot_wg_position(df=shot_data_dataframe, start=individual_survey.start, end=individual_survey.end, survey=individual_survey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Export updated site metadata to file\n",
    "\n",
    "Once you have finished identifying and adding survey metadata, save the updated metadata to a file. File name format is `[site].[new_surveys].[date].json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SITE_4_CHAR_ID = site           # 4 char site ID\n",
    "\n",
    "if not SITE_4_CHAR_ID:\n",
    "    raise ValueError(\"Please enter a 4 char site ID\")\n",
    "\n",
    "# Export site metadata to a json file\n",
    "# Add date to the file name\n",
    "date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "file_path = f\"./{SITE_4_CHAR_ID + '.new_surveys.' + date}.json\"          # Export file path you wish to store\n",
    "site_metadata.export_site(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seafloor_geodesy_mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
