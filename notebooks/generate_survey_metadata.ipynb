{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating survey metadata using waveglider positions\n",
    "\n",
    "This notebook helps a user locate the start and stop times of different surveys patterns when no survey metadata exists. If survey metadata already exists and you wish to refine start and stop times of existing metadata, please use the `refine_survey_metadata` notebook instead. \n",
    "***\n",
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import tiledb\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt, colors as mcolors, cm, dates as mdates\n",
    "from typing import List\n",
    "\n",
    "# ES-SFGTools imports\n",
    "from es_sfgtools.processing.pipeline import DataHandler\n",
    "from es_sfgtools.utils.archive_pull import list_survey_files\n",
    "from es_sfgtools.utils.metadata.site import import_site, TopLevelSiteGroups, SubLevelSiteGroups\n",
    "from es_sfgtools.utils.metadata.campaign import Survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Set survey parameters\n",
    "\n",
    "1. Input survey releated metadata including...\n",
    "* **network name** - name of network the site belongs to\n",
    "* **site name** - 4 character site name\n",
    "* **campaign name** (e.g YYYY_A_VESS) - check the metadata file to ensure you have the correct campaign name\n",
    "* **vessel type** (e.g SV2 or SV3) - this type will determine which pipeline to run\n",
    "\n",
    "2. Set the local directory you wish to use to store campaign files, logs, and tileDB arrays. It will be created if it does not yet exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input survey parameters\n",
    "network = 'cascadia-gorda'\n",
    "site = 'NCC1'\n",
    "campaign_name = '2024_A_1126'   \n",
    "vessel_type = 'SV3'             # SV2 or SV3 is supported\n",
    "\n",
    "# Set data directory path for local environment\n",
    "directory = './data/sfg'\n",
    "\n",
    "# This will creates data directory if it does not exist\n",
    "data_dir = Path(f\"{os.path.expanduser(directory)}\")\n",
    "os.makedirs(data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and inspect existing metadata\n",
    "\n",
    "Please enter the location of your **metadata file** to import data. Campaign start and end dates will be saved for setting up the `DataHandler` class in the next step.\n",
    "\n",
    "*If no campaign is displayed, ensure you have the correct campaign name in the cell above and re-run if neccessary.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the path to the metadata file\n",
    "metadata_uri = \"./site_vessels/NCC1.2025-03-20.json\"    \n",
    "\n",
    "# Load and inspect existing metadata\n",
    "print(f\"Loading metadata from {metadata_uri} ... \\n\")\n",
    "site_metadata = import_site(metadata_uri)\n",
    "\n",
    "surveys = []\n",
    "for campaign in site_metadata.campaigns:\n",
    "    if campaign.name == campaign_name:\n",
    "        start = campaign.start\n",
    "        end = campaign.end\n",
    "        print(f\"  Campaign: {campaign.name} \\n   Start: {start} \\n    End: {end}\\n\")\n",
    "\n",
    "        for survey in campaign.surveys:\n",
    "            print(f\"  Survey: {survey.id} \\n   Start: {survey.start} \\n    End: {survey.end}\")\n",
    "            surveys.append(survey)\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the data handler class with our survey parameters\n",
    "\n",
    "This will set up a `DataHandler` class using our data directory and site related information we set above. By doing this, the data handler will populate our data directory with the necessary folders and tileDB arrays. This cell also grab the correct pipeline for the vessel type specified (SV2/SV3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the DataHandler class\n",
    "data_handler = DataHandler(directory=data_dir) \n",
    "\n",
    "# Set the survey parameters\n",
    "data_handler.change_working_station(network=network, \n",
    "                                    station=site, \n",
    "                                    campaign=campaign_name, \n",
    "                                    start_date=start.date(),    # Start date of the campaign (time not accepted)\n",
    "                                    end_date=end.date())        # End date of the campaign (time not accepted)\n",
    "\n",
    "if vessel_type == 'SV3':\n",
    "    pipeline, config = data_handler.get_pipeline_sv3()\n",
    "elif vessel_type == 'SV2':\n",
    "    pipeline, config = data_handler.get_pipeline_sv2()\n",
    "else:\n",
    "    raise ValueError(f\"Vessel type {vessel_type} not recognized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the acoustic (DFOP00) files from the EarthScope archive\n",
    "\n",
    "This will go to the EarthScope archive and list files for the specific campaign. The `DataHandler` class will then add this remote file list to the catalog stored within our data directory set above. It will then download only the DFOP00 files to our data directory. \n",
    "\n",
    "*If you have already run this cell prior, it will likely not need to download the files again.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DFOP00 file list from the archive\n",
    "remote_filepaths = list_survey_files(network=network, station=site, survey=campaign_name)\n",
    "\n",
    "# Add the data to the data handler\n",
    "data_handler.add_data_remote(remote_filepaths=remote_filepaths)\n",
    "\n",
    "# Download the dfop00 files, if not already downloaded (override=False)\n",
    "data_handler.download_data(file_types='dfop00', override=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read DFOP00 files into shotdata array\n",
    "\n",
    "Using the SV pipeline chosen above, we will create an array from the DFOp00 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read DFOP00 files into shotdata array\n",
    "config.dfop00_config.override=True          # Flag to override existing data\n",
    "pipeline.config = config\n",
    "pipeline.process_dfop00()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data from array into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the shotdata array URI\n",
    "shotdata_uri = f\"{directory}/{network}/{site}/TileDB/shotdata_db.tdb\"\n",
    "\n",
    "#  Get the start and end dates of the campaign\n",
    "campaign_start = data_handler.date_range[0]\n",
    "campaign_end = data_handler.date_range[1]\n",
    "\n",
    "# Read data from the TileDB array\n",
    "print(f\"Reading dataframe from {shotdata_uri} for {campaign_start} to {campaign_end}\")\n",
    "with tiledb.open(shotdata_uri, mode=\"r\") as array:\n",
    "    shot_data_dataframe = array.df[slice(np.datetime64(campaign_start), np.datetime64(campaign_end)),:]\n",
    "\n",
    "# Show preview of the data\n",
    "shot_data_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Plot waveglider locations\n",
    "\n",
    "Now that we have our data ready, we can begin plotting waveglider locations and refining our surveys.\n",
    "\n",
    "### Set plotting functions\n",
    "We will use these 2 plotting functions to refine our surveys below. Run the next cell to set these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_en(df, surveys: List[Survey], save_as: str = None):\n",
    "    \"\"\"\n",
    "    Plots the East and North positions over time for a given dataset, with survey periods highlighted.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the survey data with columns like 'triggerTime', 'east0', and 'north0'.\n",
    "    - surveys: List of survey objects, each containing 'start', 'end', 'type', and optional 'notes'.\n",
    "    - save_as: Optional string specifying the filename to save the plot. If None, the plot is not saved.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a figure with two subplots (one for East, one for North)\n",
    "    fig, axs = plt.subplots(nrows=2, figsize=(16,10))  \n",
    "\n",
    "    # Set x and y axis labels\n",
    "    axs[0].set_ylabel(\"East (m)\")\n",
    "    axs[1].set_ylabel(\"North (m)\")\n",
    "\n",
    "    # Scatter plot for East positions\n",
    "    sc0 = axs[0].scatter(\n",
    "        df[\"triggerTime\"],\n",
    "        df[\"east0\"],\n",
    "        alpha=0.25\n",
    "    )\n",
    "    # Scatter plot for North positions\n",
    "    sc1 = axs[1].scatter(\n",
    "        df[\"triggerTime\"],\n",
    "        df[\"north0\"],\n",
    "        alpha=0.25\n",
    "    )\n",
    "\n",
    "    # Generate a rainbow colormap for the surveys\n",
    "    survey_colors = cm.rainbow(np.linspace(0, 1, len(surveys)))\n",
    "    # Highlight survey periods on both subplots\n",
    "    for ax in axs:\n",
    "        for i, survey in enumerate(surveys):\n",
    "            start = survey.start\n",
    "            end = survey.end\n",
    "            label = survey.type + \" \" + survey.notes if survey.notes else survey.type\n",
    "\n",
    "            # Highlight the survey period with a colored span\n",
    "            ax.axvspan(start, end, color=survey_colors[i], alpha=0.3, label=label)\n",
    "        \n",
    "        # Make ticks on occurrences of each month:\n",
    "        ax.xaxis.set_major_locator(mdates.DayLocator())\n",
    "        \n",
    "        # Format the x-axis to display dates in 'month-day' format\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "    \n",
    "    # Rotate x-axis labels 90 degrees\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "    # Add a legnend to the first subplot\n",
    "    axs[0].legend()\n",
    "\n",
    "    # Save the plot to a file if a filename is provided\n",
    "    if save_as is not None:\n",
    "        plt.savefig(save_as)\n",
    "        \n",
    "\n",
    "def plot_wg_position(df, survey_name: str, survey_type: str, start: datetime, end: datetime):\n",
    "    \"\"\"\n",
    "    Plots the antenna position (East vs. North) for a specific survey within a given time range.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the survey data with columns like 'triggerTime', 'east0', and 'north0'.\n",
    "    - survey_name: Name of the survey (string).\n",
    "    - survey_type: Type of the survey (string).\n",
    "    - start: Start time of the survey (datetime object).\n",
    "    - end: End time of the survey (datetime object).\n",
    "    \"\"\"\n",
    "    # Filter the DataFrame for the specified time range\n",
    "    temp_df = df[df['triggerTime']>=start]\n",
    "    temp_df = temp_df[df['triggerTime']<=end]\n",
    "\n",
    "    # Create a figure and axis for the plot\n",
    "    fig, ax = plt.subplots(figsize=(16,10))\n",
    "\n",
    "    # Set the title of the plot and the filename for saving the figure\n",
    "    title = f\"{survey_name} {survey_type} from {start.isoformat()} to {end.isoformat()}\"\n",
    "    save_as = f\"{survey_name}_{survey_type}.png\"\n",
    "    fig.suptitle(title)\n",
    "\n",
    "    # Set the x and y axis labels\n",
    "    ax.set_xlabel(\"East (m)\")\n",
    "    ax.set_ylabel(\"North (m)\")\n",
    "\n",
    "    # Optional: Plot the origin point (?)\n",
    "    #ax.scatter(0, 0, label=\"Origin\", color=\"magenta\",s=100)\n",
    "\n",
    "    # Convert trigger times to timestamps and scale them for colormap normalization\n",
    "    colormap_times = temp_df[\"triggerTime\"].apply(lambda x:x.timestamp()).to_numpy()\n",
    "    colormap_times_scaled = (colormap_times - colormap_times.min())/3600\n",
    "\n",
    "    # Normalize the colormap to the range of scaled times\n",
    "    norm = mcolors.Normalize(\n",
    "        vmin=0,\n",
    "        vmax=(colormap_times.max() - colormap_times.min()) / 3600,\n",
    "    )\n",
    "\n",
    "    # Scatter plot of East vs. North positions, colored by time\n",
    "    sc = ax.scatter(\n",
    "        temp_df[\"east0\"],\n",
    "        temp_df[\"north0\"],\n",
    "        c=colormap_times_scaled,\n",
    "        cmap=\"viridis\",\n",
    "        label=\"Antenna Position\",\n",
    "        norm=norm,\n",
    "        alpha=0.25\n",
    "    )\n",
    "\n",
    "    # Add a colorbar to indicate time in hours\n",
    "    cbar = plt.colorbar(sc,label=\"Time (hr)\",norm=norm)\n",
    "\n",
    "    # Add a legend to the plot\n",
    "    ax.legend()\n",
    "\n",
    "    # Save the plot to a file\n",
    "    plt.savefig(save_as)\n",
    "\n",
    "    # Print the start and end times of the filtered data\n",
    "    print(temp_df.triggerTime.iloc[0].isoformat(), temp_df.triggerTime.iloc[-1].isoformat())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the surveys available\n",
    "\n",
    "If you wish to review the surveys available, run the next cell. You will need to survey IDs to plot individual surveys. The typical ID is in the format `CAMPAIGN_NAME_INTERVAL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {len(surveys)} surveys in the campaign {campaign_name} \\n\")\n",
    "for survey in surveys:\n",
    "    print(survey.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the full campaign with all surveys\n",
    "\n",
    "This next cell takes the start and end date of the shot data dataframe and plots the east and north positions over time as welll as the waveglider map positions. If surveys already exist within the metadata, they are shown and labels on the east/north plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust to remove any junk data at beginning or end if needed\n",
    "start = shot_data_dataframe.triggerTime.iloc[0] + timedelta(hours=0)\n",
    "end = shot_data_dataframe.triggerTime.iloc[-1]\n",
    "\n",
    "temp_df = shot_data_dataframe[shot_data_dataframe['triggerTime']>=start]\n",
    "temp_df = temp_df[shot_data_dataframe['triggerTime']<=end]\n",
    "\n",
    "# Plot the East and North positions over time\n",
    "plot_en(temp_df, surveys)\n",
    "\n",
    "# Plot the waveglider position\n",
    "plot_wg_position(shot_data_dataframe, f\"{site}_{campaign_name}\", \"all\", start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot original survey\n",
    "\n",
    "Now that we have plotted the full campaign, lets narrow down on an individual survey. If no surveys exist yet, skip this section and move on to creating your own survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the survey to plot\n",
    "survey_name = f\"{campaign_name}_1\"\n",
    "survey = next((survey for survey in surveys if survey.id == survey_name), None)\n",
    "if not survey:\n",
    "    raise ValueError(f\"Survey {survey_name} not found in the list of surveys.\")\n",
    "else:\n",
    "    print(f\"Plotting survey {survey_name} ...\")\n",
    "\n",
    "plot_en(temp_df, [survey])\n",
    "plot_wg_position(df=shot_data_dataframe, survey_name=survey.id, survey_type=survey.type, start=survey.start, end=survey.end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refine the original survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update these for the survey you want to plot\n",
    "new_start = survey.start + timedelta(hours=0, minutes=0)\n",
    "new_end = survey.end - timedelta(hours=0, minutes=0)\n",
    "\n",
    "plot_en(temp_df, [survey])\n",
    "plot_wg_position(df=shot_data_dataframe, survey_name=survey.id, survey_type=survey.type, start=new_start, end=new_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update original survey metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the survey metadata, ID is required, updating start and end times\n",
    "update_survey_data = {\"id\": survey.id, \"start\": new_start.isoformat(), \"end\": new_end.isoformat()}\n",
    "\n",
    "# Update the survey metadata in the site metadata\n",
    "site_metadata.run_sub_component(component_type=TopLevelSiteGroups.CAMPAIGNS, component_name=campaign_name,\n",
    "                            sub_component_type=SubLevelSiteGroups.SURVEYS, sub_component_metadata=update_survey_data,\n",
    "                            update=True)\n",
    "\n",
    "plot_en(temp_df, surveys, save_as=f\"{site}_{campaign_name}_surveys.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot all survey maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for survey in surveys:\n",
    "    plot_wg_position(df=shot_data_dataframe, survey_name=survey.id, survey_type=survey.type, start=survey.start, end=survey.end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export updated site metadata to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SITE_4_CHAR_ID = \"blah\" # 4 char site ID\n",
    "\n",
    "if not SITE_4_CHAR_ID:\n",
    "    raise ValueError(\"Please enter a 4 char site ID\")\n",
    "\n",
    "# Export site metadata to a json file\n",
    "# Add date to the file name\n",
    "date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "file_path = f\"./{SITE_4_CHAR_ID + '.' + date}.json\"          # Export file path you wish to store\n",
    "site_metadata.export_site(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seafloor_geodesy_mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
