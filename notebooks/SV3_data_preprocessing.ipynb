{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SV3 Data Preprocessing \n",
    "\n",
    "This notebook runs a user through the steps to select a campaign and preprocess all the raw data into the inputs necessary to run GARPOS.  \n",
    "\n",
    "It is specific to the steps for processing SV3 data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from es_sfgtools.processing.pipeline import DataHandler\n",
    "from es_sfgtools.utils.archive_pull import load_site_metadata\n",
    "from es_sfgtools.utils.loggers import BaseLogger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm required environment variables are set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this must be set correctly for GO executables to translate novatel to rinex\n",
    "\n",
    "#Linux\n",
    "!echo $LD_LIBRARY_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this confirms PRIDE-PPPAR is in the PATH\n",
    "!which pdp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Initial Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Browse available campaigns from the community archive and select target\n",
    "- Locate the campaign of interest in https://gage-data.earthscope.org/archive/seafloor, and note the `network`, `station`, and `campaign` names, which will be input in the cell below.  \n",
    "- Note: the cascadia-gorda raw data is currently hidden (by request) but still usable, here are the available campaigns\n",
    "\n",
    "|  | GCC1 | NBR1 | NCC1 |\n",
    "|---|---|---|---|\n",
    "| **2022** |2022_A_1065 | 2022_A_1065  |  2022_A_1065 |\n",
    "| **2023** |  2023_A_1063 | 2023_A_1063 | 2023_A_1063 |\n",
    "| **2024** |  2024_A_1126 |  2024_A_1126 | 2024_A_1126 |\n",
    "- In order to use this notebook to process new campaigns, the data must first be submitted and made available from the community archive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input survey parameters\n",
    "network='cascadia-gorda'\n",
    "site='NCC1'\n",
    "campaign='2023_A_1063'\n",
    "\n",
    "# Set data directory path for local environment\n",
    "data_dir = Path(f\"{os.path.expanduser('~/data/sfg')}\")\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "#### USE THE FOLLOWING DEFAULTS UNLESS DESIRED####\n",
    "data_handler = DataHandler(directory=data_dir)\n",
    "data_handler.change_working_station(network=network, station=site, campaign=campaign)\n",
    "BaseLogger.set_dir(data_handler.station_log_dir)\n",
    "\n",
    "pipeline, config = data_handler.get_pipeline_sv3()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Inventory available data and its location\n",
    "This step checks the archive and creates an inventory of whats available for a given campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.update_catalog_from_archive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what files already exist locally\n",
    "data_type_counts = data_handler.get_dtype_counts()\n",
    "print(f\"Local data directory contains the following:\")\n",
    "for item in data_type_counts.items():\n",
    "    print(f\"    {item[0]}: {item[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Pull data from remote archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download files if not already present\n",
    "Observable file types depend on whether data was collected with an SV2 or SV3 waveglider.  \n",
    "You can download the default file types, or specify a specific type to download.\n",
    "\n",
    "![Alt text](garpos_flow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Download default file types for SV2 or SV3\n",
    "\n",
    "data_handler.download_data()\n",
    "\n",
    "####### OR Download the files by type\n",
    "\n",
    "# data_handler.download_data(file_type='sonardyne', show_details=False)\n",
    "# data_handler.download_data(file_type='novatel', show_details=False)\n",
    "# data_handler.download_data(file_type='master', show_details=False)\n",
    "# data_handler.download_data(file_type='svpavg', show_details=False)\n",
    "# data_handler.download_data(file_type='leverarm', show_details=False)\n",
    "# data_handler.download_data(file_types='dfop00')\n",
    "# data_handler.download_data(file_types='novatel770')\n",
    "# data_handler.download_data(file_types='novatel000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4.  Process raw files and build GARPOS observation input (shotdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Read DFOP00 files containing ping/reply sequences, write them to the shotdata tiledb array\n",
    "Config options: \n",
    "- override: bool = Field(False, title=\"Flag to Override Existing Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.dfop00_config.override=False\n",
    "pipeline.config = config\n",
    "pipeline.process_dfop00()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Read the novatel range messages and normalize the observations to tiledb\n",
    "Config options: \n",
    "- override: bool = Field(False, title=\"Flag to Override Existing Data\")\n",
    "- n_processes: int = Field(default_factory=cpu_count, title=\"Number of Processes to Use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config.novatel_config.override=False\n",
    "pipeline.config = config\n",
    "pipeline.pre_process_novatel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Generate daily rinex 2.11 files from the tiledb observations\n",
    "Config options: \n",
    "- override: bool = Field(False, title=\"Flag to Override Existing Data\")\n",
    "- override_products_download: bool = Field(False, title=\"Flag to Override Existing Products Download\")\n",
    "- n_processes: int = Field(default_factory=cpu_count, title=\"Number of Processes to Use\")\n",
    "- settings_path: Optional[Path] = Field(\"\", title=\"Settings Path\")\n",
    "- time_interval: Optional[int] = Field(1, title=\"Tile to Rinex Time Interval [h]\")\n",
    "- processing_year: Optional[int] = Field(default=-1,description=\"Processing year to query tiledb\",le=2100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config.rinex_config.override=False\n",
    "pipeline.config = config\n",
    "pipeline.get_rinex_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Process the rinex files using PRIDE-PPPAR to solve for waveglider positions\n",
    "Config options: \n",
    "- system (str): The GNSS system(s) to use. Default is \"GREC23J\" which is “GPS/GLONASS/Galileo/BDS/BDS-2/BDS-3/QZSS”.\n",
    "        frequency (list): The GNSS frequencies to use. Default is [\"G12\", \"R12\", \"E15\", \"C26\", \"J12\"]. Refer to Table 5-4 in PRIDE-PPP-AR v.3.0 manual for more options.\n",
    "- loose_edit (bool): Disable strict editing mode, which should be used when high dynamic data quality is poor. Default is True.\n",
    "- cutoff_elevation (int): The elevation cutoff angle in degrees (0-60 degrees). Default is 7.\n",
    "- start (datetime): The start time used for processing. Default is None.\n",
    "- end (datetime): The end time used for processing. Default is None.\n",
    "- interval (float): Processing interval, values range from 0.02s to 30s. If this item is not specified and the configuration file is specified, the processing interval in the configuration file will be read, otherwise, the sampling rate of the observation file is used by default.\n",
    "- high_ion (bool): Use 2nd ionospheric delay model with CODE's GIM product. When this option is not entered, no higher-order ionospheric correction is performed. Default is False.\n",
    "- tides (str): Enter one or more of \"S\" \"O\" \"P\", e.g SO for solid, ocean, and polar tides. Default is \"SOP\", which uses all tides.\n",
    "- override: bool = Field(False, title=\"Flag to Override Existing Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "config.pride_config.override=False\n",
    "pipeline.config = config   \n",
    "pipeline.process_rinex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Read the PRIDE position results (kin) files and write them to tiledb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.process_kin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Merge the PPP position solutions back into the shotdata.  \n",
    "This step interpolates 1 hz position solutions in order to accurately position the waveglider for each ping/reply.  This step can take some time.\n",
    "\n",
    "Config options: \n",
    "- override: bool = Field(False, title=\"Flag to Override Existing Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.position_update_config.override=False\n",
    "pipeline.config = config  \n",
    "pipeline.update_shotdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
