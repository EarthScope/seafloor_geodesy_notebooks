{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import boto3\n",
    "import logging\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "os.environ[\"GARPOS_DIR\"] = (\"./dev/garpos\")\n",
    "# path_cmd = \"/Users/franklyndunbar/.PRIDE_PPPAR_BIN\"\n",
    "# os.environ[\"PATH\"] += os.pathsep + path_cmd\n",
    "\n",
    "from es_sfgtools.pipeline import DataHandler,DATA_TYPE,FILE_TYPE,DataCatalog\n",
    "from es_sfgtools.garpos_tools import functions as garpos_functions\n",
    "from es_sfgtools.garpos_tools import schemas as garpos_schemas\n",
    "from es_sfgtools.utils.gage_data import (\n",
    "    generate_gage_data_survey_url, \n",
    "    list_files_from_gage_data,\n",
    "    get_survey_file_dict\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Establish data storage and catalog directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"./data\")\n",
    "data_handler = DataHandler(working_dir=data_dir)\n",
    "# Set Logger Location\n",
    "logging.basicConfig(level=logging.INFO, filemode=\"w\", filename=data_dir/\"dev_datahandler.log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Initial User Input to select Observation Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Browse available surveys from the community archive\n",
    "- Locate the survey of interest in https://gage-data.earthscope.org/archive/seafloor, and note the `network`, `station`, and `survey` names\n",
    "- In order to use this notebook to process new surveys, the data must first be submitted and made available from the community archive "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Select a survey and view available files\n",
    "- User inputs `network`, `station`, and `survey`\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network='aleutian'\n",
    "site='SEM1'\n",
    "survey='2018_A_SFG1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = generate_gage_data_survey_url(network, site, survey)\n",
    "remote_filepaths = list_files_from_gage_data(url)\n",
    "remote_filepaths\n",
    "#survey_files = get_survey_file_dict(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Add the remote location of discovered files to the data catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_counts = data_handler.add_campaign_data(\n",
    "    network=network, station=site, survey=survey, remote_filepaths=remote_filepaths)\n",
    "print(dtype_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 Use remote locations to download and store data locally "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.download_campaign_data(network=network, station=site, survey=survey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 Process raw data to final product \n",
    "![Alt text](garpos_flow.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Take all acoustic parent files and generate acoustic df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.process_acoustic_data(network=network, station=site, survey=survey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Take all IMU parent files and generate IMU df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.process_imu_data(network=network, station=site, survey=survey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Take all GNSS parent files and generate GNSS df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.process_gnss_data(network=network, station=site, survey=survey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Take all site parent files and generate the site configuration data, which includes ATD offset, sound-velocity DF, and transponder info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.process_siteconfig(network=network, station=site, survey=survey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 Merge sessions for GARPOS (each set of temporally identical IMU,Acoustic, and GNSS data frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Get a df of all session data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_df = data_handler.get_observation_session_data(network=network, station=site, survey=survey,plot=True)\n",
    "session_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Generate a dict. of all data corresponding to the temporal groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_paths = data_handler.group_observation_session_data(session_df,timespan='DAY')\n",
    "print(json.dumps(df_paths, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Get Site, ATDOffset, and SVP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_config = data_handler.get_site_config(network=network, station=site, survey=survey)\n",
    "site_config.name = network + \"_\" + site + \"_\" + survey\n",
    "atd_offset = data_handler.get_atd_offset(network=network, station=site, survey=survey)\n",
    "svp_data:pd.DataFrame = data_handler.get_svp_data(network=network, station=site, survey=survey)\n",
    "# Get the first day of data\n",
    "observables = df_paths[\"2018-05-14 00:00:00\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Merge imu, acoustic, and gnss data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_imu = pd.concat([pd.read_csv(path) for path in observables[\"imu\"]])\n",
    "merged_acoustic = pd.concat([pd.read_csv(path) for path in observables[\"acoustic\"]])\n",
    "merged_gnss = pd.concat([pd.read_csv(path) for path in observables[\"gnss\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_gnss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_imu.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_acoustic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 Convert generic data into GARPOS specific formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "garpos_input = garpos_functions.garpos_input_from_site_obs(\n",
    "    site_config=site_config,\n",
    "    atd_offset=atd_offset,\n",
    "    sound_velocity=svp_data,\n",
    "    imu_data=merged_imu,\n",
    "    acoustic_data=merged_acoustic,\n",
    "    gnss_data=merged_gnss,\n",
    ")\n",
    "garpos_fixed = garpos_schemas.GarposFixed()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for transponder in site_config.transponders:\n",
    "    print(transponder.position_llh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.plot_site_config(site_config=site_config, zoom=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "garpos_functions.plot_enu_llh_side_by_side(garpos_input=garpos_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfg",
   "language": "python",
   "name": "sfg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
