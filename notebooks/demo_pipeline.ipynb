{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gottlieb/working/GIT/es_sfgtools/src/es_sfgtools/pipeline/temp.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "os.environ[\"GARPOS_DIR\"] = (\"./dev/garpos\")\n",
    "path_cmd = \"/Users/gottlieb/.PRIDE_PPPAR_BIN\"\n",
    "os.environ[\"PATH\"] += os.pathsep + path_cmd\n",
    "\n",
    "from es_sfgtools.pipeline import DataHandler,DATA_TYPE,FILE_TYPE,DataCatalog\n",
    "#from es_sfgtools.garpos_tools import functions as garpos_functions\n",
    "#from es_sfgtools.garpos_tools import schemas as garpos_schemas\n",
    "from es_sfgtools.utils.gage_data import (\n",
    "    list_survey_files\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Initial Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Browse available surveys from the community archive and select target\n",
    "- Locate the survey of interest in https://gage-data.earthscope.org/archive/seafloor, and note the `network`, `station`, and `survey` names, which will be input in the cell below.\n",
    "- In order to use this notebook to process new surveys, the data must first be submitted and made available from the community archive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data Handler initialized, data will be stored in /Users/gottlieb/working/GIT/seafloor_geodesy_notebooks/notebooks/data/aleutian_IVB1_2018_A_SFG1\n"
     ]
    }
   ],
   "source": [
    "network='aleutian'\n",
    "site='IVB1'\n",
    "survey='2018_A_SFG1'\n",
    "\n",
    "#### USE THE FOLLOWING DEFAULTS UNLESS DESIRED####\n",
    "\n",
    "# Set data directory\n",
    "data_dir = Path(f\"{os.getcwd()}/data/{network}_{site}_{survey}\")\n",
    "\n",
    "# Set Logger Location\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    #format=\"{asctime} - {levelname} - {message}\",\n",
    "                    format=\"{message}\",\n",
    "                    style=\"{\",\n",
    "                    datefmt=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# Initialize the data_handler\n",
    "data_handler = DataHandler(working_dir=data_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Inventory available data and its location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found under https://gage-data.earthscope.org/archive/seafloor/aleutian/IVB1/2018_A_SFG1/raw:\n",
      "    1 master file(s)\n",
      "    73 novatel file(s)\n",
      "    73 offload file(s)\n",
      "    73 sonardyne file(s)\n",
      "    1 lever_arms file(s)\n",
      "    2 ctd file(s)\n"
     ]
    }
   ],
   "source": [
    "# Generate a list of files available from remote archive\n",
    "#TODO: implement options for raw vs intermediate vs processed \n",
    "remote_filepaths = list_survey_files(network=network, station=site, survey=survey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local data directory contains the following:\n",
      "    novatel: 73\n",
      "    sonardyne: 73\n",
      "    imu: 73\n",
      "    acoustic: 73\n",
      "    master: 1\n",
      "    svpavg: 1\n"
     ]
    }
   ],
   "source": [
    "# See what files exist locally\n",
    "data_type_counts = data_handler.get_local_counts()\n",
    "print(f\"Local data directory contains the following:\")\n",
    "for item in data_type_counts.items():\n",
    "    print(f\"    {item[0]}: {item[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Pull data from remote archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File type not recognized for https://gage-data.earthscope.org/archive/seafloor/aleutian/IVB1/2018_A_SFG1/raw/ctd/CTD_SITE2_Ch_Mi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalog now contains the following:\n",
      "    novatel: 73\n",
      "    offload: 73\n",
      "    sonardyne: 73\n",
      "    master: 1\n",
      "    leverarm: 1\n",
      "    svpavg: 1\n"
     ]
    }
   ],
   "source": [
    "# TODO: Detail counts of files local vs only remote\n",
    "#Add found remote files to the catalog\n",
    "data_handler.add_campaign_data(network=network, station=site, survey=survey, remote_filepaths=remote_filepaths)\n",
    "data_type_counts = data_handler.get_dtype_counts()\n",
    "print(f\"Catalog now contains the following:\")\n",
    "for item in data_type_counts.items():\n",
    "    print(f\"    {item[0]}: {item[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select files types for downloading\n",
    "Observable file types depend on whether data was collected with an SV2 or SV3 waveglider.  \n",
    "\n",
    "![Alt text](garpos_flow.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data directory currently contains 73 files of type sonardyne\n",
      "Downloading 0 missing files of type sonardyne\n",
      "No files downloaded\n",
      "Data directory currently contains 73 files of type novatel\n",
      "Downloading 0 missing files of type novatel\n",
      "No files downloaded\n",
      "Data directory currently contains 1 files of type master\n",
      "Downloading 0 missing files of type master\n",
      "No files downloaded\n",
      "Data directory currently contains 1 files of type svpavg\n",
      "Downloading 0 missing files of type svpavg\n",
      "No files downloaded\n"
     ]
    }
   ],
   "source": [
    "# Download the files by type\n",
    "data_handler.download_campaign_data(network=network, station=site, survey=survey, file_type='sonardyne')\n",
    "data_handler.download_campaign_data(network=network, station=site, survey=survey, file_type='novatel')\n",
    "data_handler.download_campaign_data(network=network, station=site, survey=survey, file_type='master')\n",
    "data_handler.download_campaign_data(network=network, station=site, survey=survey, file_type='svpavg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4. Parse/Process raw data to processing input schemas\n",
    "\n",
    "- 4.1 Parse acoustic observations into AcousticDataFrames\n",
    "- 4.2 Parse IMU observations into IMUDataFrames\n",
    "- 4.3 Process GNSS observables to generate PositionDataFrames\n",
    "    - Parse RANGE-A novatel messages, build RINEX files\n",
    "    - Run PRIDE-PPP-AR on RINEX, generate Kin files\n",
    "    - Parse Kin files into PositionDataFrames\n",
    "- 4.4 Parse metadata files into SiteConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Take all acoustic parent files and generate acoustic df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No unprocessed data found in catalog for types ['dfpo00']\n",
      "All available instances of processing type dfpo00 to type acoustic have been processed\n",
      "No unprocessed data found in catalog for types ['sonardyne']\n",
      "All available instances of processing type sonardyne to type acoustic have been processed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No unprocessed data found in catalog for types ['dfpo00']\n",
      "All available instances of processing type dfpo00 to type acoustic have been processed\n",
      "No unprocessed data found in catalog for types ['sonardyne']\n",
      "All available instances of processing type sonardyne to type acoustic have been processed\n"
     ]
    }
   ],
   "source": [
    "data_handler.process_acoustic_data(network=network, station=site, survey=survey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Take all IMU parent files and generate IMU df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No unprocessed data found in catalog for types ['dfpo00']\n",
      "All available instances of processing type dfpo00 to type imu have been processed\n",
      "All available instances of processing type novatel to type imu have been processed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No unprocessed data found in catalog for types ['dfpo00']\n",
      "All available instances of processing type dfpo00 to type imu have been processed\n",
      "All available instances of processing type novatel to type imu have been processed\n"
     ]
    }
   ],
   "source": [
    "data_handler.process_imu_data(network=network, station=site, survey=survey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Take all GNSS parent files and generate GNSS df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.process_gnss_data(network=network, station=site, survey=survey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Take all site parent files and generate the site configuration data, which includes ATD offset, sound-velocity DF, and transponder info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.process_siteconfig(network=network, station=site, survey=survey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 Merge sessions for GARPOS (each set of temporally identical IMU,Acoustic, and GNSS data frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Get a df of all session data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_df = data_handler.get_observation_session_data(network=network, station=site, survey=survey,plot=True)\n",
    "session_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Generate a dict. of all data corresponding to the temporal groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_paths = data_handler.group_observation_session_data(session_df,timespan='DAY')\n",
    "print(json.dumps(df_paths, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Get Site, ATDOffset, and SVP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_config = data_handler.get_site_config(network=network, station=site, survey=survey)\n",
    "site_config.name = network + \"_\" + site + \"_\" + survey\n",
    "atd_offset = data_handler.get_atd_offset(network=network, station=site, survey=survey)\n",
    "svp_data:pd.DataFrame = data_handler.get_svp_data(network=network, station=site, survey=survey)\n",
    "# Get the first day of data\n",
    "observables = df_paths[\"2018-05-14 00:00:00\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Merge imu, acoustic, and gnss data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_imu = pd.concat([pd.read_csv(path) for path in observables[\"imu\"]])\n",
    "merged_acoustic = pd.concat([pd.read_csv(path) for path in observables[\"acoustic\"]])\n",
    "merged_gnss = pd.concat([pd.read_csv(path) for path in observables[\"gnss\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_gnss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_imu.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_acoustic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 Convert generic data into GARPOS specific formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "garpos_input = garpos_functions.garpos_input_from_site_obs(\n",
    "    site_config=site_config,\n",
    "    atd_offset=atd_offset,\n",
    "    sound_velocity=svp_data,\n",
    "    imu_data=merged_imu,\n",
    "    acoustic_data=merged_acoustic,\n",
    "    gnss_data=merged_gnss,\n",
    ")\n",
    "garpos_fixed = garpos_schemas.GarposFixed()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for transponder in site_config.transponders:\n",
    "    print(transponder.position_llh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.plot_site_config(site_config=site_config, zoom=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "garpos_functions.plot_enu_llh_side_by_side(garpos_input=garpos_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "es_sfgtools_dev",
   "language": "python",
   "name": "es_sfgtools_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
