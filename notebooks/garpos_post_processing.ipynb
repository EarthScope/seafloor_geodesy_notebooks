{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRAFT POST PROCESSING WORKFLOW\n",
    "This notebook mocks up the front end user interactions with the seafloor geodesy code.  The final version of this will be a major deliverable to the USGS on or before Sept 31, 2024.\n",
    "\n",
    "Requirements for Minimum Viable Product:\n",
    "- Earthscope will deliver a suite of notebooks and a containerized environment for the USGS to run end-to-end GARPOS seafloor positioning in AWS.  The software must support the data preparation steps and processing of data from a GNSS-A survey performed using either an SV2 or SV3 system.  A survey is defined here as a set of observations that will be processed as one or more sessions and merged to generate a single position for either a single transponder or an array center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from es_sfgtools.utils.gage_data import (\n",
    "    generate_gage_data_survey_url, \n",
    "    get_survey_file_dict\n",
    "    )\n",
    "\n",
    "data_directory = '../data' \n",
    "token_path = '.' # directory where the token will be stored (default is the current directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Initial User Input to select Observation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Browse available surveys from the community archive\n",
    "- Locate the survey of interest in https://gage-data.earthscope.org/archive/seafloor, and note the `network`, `station`, and `survey` names\n",
    "- In order to use this notebook to process new surveys, the data must first be submitted and made available from the community archive "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Select a survey and view available files\n",
    "- User inputs `network`, `station`, and `survey`\n",
    "- Notebook locates and presents a summary available files for that survey\n",
    "- You will be asked to log in with your EarthScope credentials during your first interaction with the archive server. The token will be refreshed every 8 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found:\n",
      "    1 master file(s)\n",
      "    163 bcnovatel file(s)\n",
      "    163 bcsonardyne file(s)\n",
      "    1 lever_arms file(s)\n",
      "    2 ctd file(s)\n"
     ]
    }
   ],
   "source": [
    "network = 'aleutian'\n",
    "station = 'SEM1'\n",
    "survey = '2018_A_SFG1'\n",
    "\n",
    "url = generate_gage_data_survey_url(network, station, survey)\n",
    "survey_files = get_survey_file_dict(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.  Prepare observation data.  \n",
    "In order to support variable Session lengths, we will first build multiple DataFrames based on raw file length (1hr for SV2, variable for SV3), and then merge those into DataFrames for the entire survey period.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Acoustic Data Prep\n",
    "- Loop through all raw acoustic files in survey, read in data to AcousticDataFrames, and then merge all those into a single AcousticDataFrame.\n",
    "- Save to csv, implement logic to load from csv if exists already."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 IMU Data Prep\n",
    "- Loop through all raw IMU files in survey, read in data to ImuDataFrames, and then merge all those into a single ImuDataFrame\n",
    "- Save to csv, implement logic to load from csv if exists already."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 GNSS Novatel messages to Rinex\n",
    "- Loop through each raw GNSS observable file, writing a RINEX file for each.  \n",
    "- Present metadata to be used for RINEX headers, provide option to update if incorrect.\n",
    "- If ShotDataFrame csv exists, can skip 2.3 - 2.6 and load from csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 GNSS Rinex to Kin\n",
    "- Loop through each rinex files, run PRIDE-PPP, generate and store Kin files.  \n",
    "- Expose parameters for PRIDE-PPP function pdp3 if user wants additional control over waveglider position processing.\n",
    "- If ShotDataFrame csv exists, can skip 2.3 - 2.6 and load from csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Build PositionDataFrame\n",
    "- Read in the Kin files to PositionDataFrames, and merge those into a single PositionDataFrame.\n",
    "- If ShotDataFrame csv exists, can skip 2.3 - 2.6 and load from csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Build ShotDataFrame\n",
    "- Combine the AcousticDataFrame, ImuDataFrame, and PositionDataFrame into a single ShotDataFrame, interpolating the IMU and Position data to match the 15s sample interval in the Acoustic Data.  \n",
    "- Store this ShotDataFrame as csv or tab-delimited ascii.\n",
    "- If ShotDataFrame csv exists, can skip 2.3 - 2.6 and load from csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Select and prepare site config data (CTD, lever arms, and master files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Load CTD\n",
    "- Load .cnv file if present in the survey directory, present relevant metadata from header so user knows what CTD this is\n",
    "- Allow user to specify different CTD if desired, or none present in directory  \n",
    "- Parse CTD and build SoundVelocityProfile    \n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Verify/select ATD Offset\n",
    "- Load lever_arms file if present in the survey directory, display offset values for sanity check\n",
    "- Allow user to specify different lever arms file if desired, or none present in directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Verify/select Master File\n",
    "- Load master file if present in the survey directory, display relevant metadata for sanity check\n",
    "- Allow user to specify different master file if desired, or none present in directory \n",
    "- Build GarposSite from lever_arms and master files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Run GARPOS Sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Verify processing start and stop times\n",
    "- visualize the waveglider position data\n",
    "    - allow user to trim start/end times based on survey pattern, differentiate between circle drives and fixed point patterns within a given survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Enter GARPOS parameters\n",
    "- Enter the desired garpos processing session length (ie 1 hr, 24 hrs)\n",
    "- Show default hyper-parameters used for GARPOS processing, allow user to override\n",
    "- Select whether computing array center or single transponder position  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Run GARPOS \n",
    "- Slice the ShotDataFrame into chunks matching the Session length.   \n",
    "- Process each session and store all results as csv / tab-delimeted ascii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 View residuals\n",
    "- make a simple plot of GARPOS epoch by epoch residuals for the whole survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Merge GARPOS Sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Run session merge\n",
    "- Use GARPOS to merge the session results into a single survey result.  \n",
    "- Store results as csv/tab-delimited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfg",
   "language": "python",
   "name": "sfg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
